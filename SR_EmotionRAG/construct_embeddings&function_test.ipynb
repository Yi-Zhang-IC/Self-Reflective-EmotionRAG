{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vipuser/miniconda3/envs/emoenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "import json \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import openai\n",
    "from random import randint\n",
    "from typing import List\n",
    "from tqdm import tqdm \n",
    "from openai import OpenAI\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "def load_local_roleplay_model(model_path=\"../models/OpenHermes-2.5-Mistral-7B\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"auto\",  # automatically assigns GPU if available\n",
    "        torch_dtype=torch.float16  # you can change this to torch.bfloat16 or float32\n",
    "    )\n",
    "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.28s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "OpenHermes_pipeline = load_local_roleplay_model(\"../models/OpenHermes-2.5-Mistral-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_llm_generator(local_pipeline, prompt: str, max_new_tokens: int = 800, temperature=0.8, top_p=0.92):\n",
    "    try:\n",
    "        result = local_pipeline(\n",
    "            prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            return_full_text=False\n",
    "        )\n",
    "        return [{\"generated_text\": result[0][\"generated_text\"].strip()}]\n",
    "    except Exception as e:\n",
    "        print(\"Local LLM generation failed:\", e)\n",
    "        return [{\"generated_text\": \"\"}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 14 files: 100%|██████████| 14/14 [00:00<00:00, 5282.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/emotion-retrieval-embeddings/emotional_embeddings/bge-base-en-v1.5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(\"BAAI/bge-base-en-v1.5\", local_dir=\"../models/bge-base-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# snapshot_download(\n",
    "#     repo_id=\"BAAI/bge-reranker-base\",\n",
    "#     local_dir=\"../models/bge-reranker-base\",\n",
    "#     local_dir_use_symlinks=False  # safer for copying in environments like WSL or Docker\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning characters in /root/emotion-retrieval-embeddings/database\n",
      "Skipping system_prompts.json — no memory.json found\n",
      "Embedding: minerva_mcgonagall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [00:00<00:00, 20.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minerva_mcgonagall: 224 memories embedded and saved.\n",
      "Embedding: harry_potter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 19/19 [00:00<00:00, 24.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harry_potter: 581 memories embedded and saved.\n",
      "Embedding: ron_weasley\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [00:00<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ron_weasley: 197 memories embedded and saved.\n",
      "Embedding: luna_lovegood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luna_lovegood: 77 memories embedded and saved.\n",
      "Embedding: albus_dumbledore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albus_dumbledore: 256 memories embedded and saved.\n",
      "Embedding: severus_snape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severus_snape: 236 memories embedded and saved.\n",
      "Embedding: hermione_granger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [00:00<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hermione_granger: 211 memories embedded and saved.\n",
      "Embedding: draco_malfoy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draco_malfoy: 86 memories embedded and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATABASE_DIR = Path(\"../database\")\n",
    "LOCAL_SEMANTIC_MODEL_PATH = Path(\"../models/bge-base-en-v1.5\")  # <-- use local model directory\n",
    "SEMANTIC_MODEL = SentenceTransformer(str(LOCAL_SEMANTIC_MODEL_PATH))  # load model from disk\n",
    "\n",
    "def embed_character_memories(character: str):\n",
    "    character_dir = DATABASE_DIR / character\n",
    "    memory_file = character_dir / \"memory.json\"\n",
    "    assert memory_file.exists(), f\"No memory.json found for {character}\"\n",
    "\n",
    "    # Load memory data\n",
    "    with open(memory_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        memory_data = json.load(f)\n",
    "\n",
    "    # Format with instruction prefix\n",
    "    texts = [f\"passage: {m['text']}\" for m in memory_data]\n",
    "\n",
    "    # Embed with tqdm progress\n",
    "    embeddings = SEMANTIC_MODEL.encode(texts, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    # Save embeddings\n",
    "    torch.save(embeddings, character_dir / \"embeddings.pt\")\n",
    "\n",
    "    # Save ID map for retrieval\n",
    "    id_map = {\n",
    "        str(i): {\n",
    "            \"text\": m[\"text\"],\n",
    "            \"source_paragraph_index\": m.get(\"source_paragraph_index\", i)\n",
    "        } for i, m in enumerate(memory_data)\n",
    "    }\n",
    "    with open(character_dir / \"id_map.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(id_map, f, indent=2)\n",
    "\n",
    "    print(f\"{character}: {len(memory_data)} memories embedded and saved.\")\n",
    "\n",
    "def embed_all_characters():\n",
    "    print(f\"Scanning characters in {DATABASE_DIR.resolve()}\")\n",
    "    for character in os.listdir(DATABASE_DIR):\n",
    "        char_path = DATABASE_DIR / character\n",
    "        if (char_path / \"memory.json\").exists():\n",
    "            print(f\"Embedding: {character}\")\n",
    "            embed_character_memories(character)\n",
    "        else:\n",
    "            print(f\"Skipping {character} — no memory.json found\")\n",
    "\n",
    "embed_all_characters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Local model paths\n",
    "LOCAL_SEMANTIC_MODEL_PATH = \"../models/bge-base-en-v1.5\"\n",
    "RERANKER_MODEL_PATH = \"../models/bge-reranker-base\"\n",
    "DATABASE_PATH = Path(\"../database\")\n",
    "\n",
    "# Load models\n",
    "EMBED_MODEL = SentenceTransformer(LOCAL_SEMANTIC_MODEL_PATH)\n",
    "RERANKER = CrossEncoder(RERANKER_MODEL_PATH)\n",
    "\n",
    "def retrieve_top_k_memories(character: str, query: str, k: int = 10, rerank_top: int = 3, rerank_score_threshold: float = 0.0):\n",
    "    char_dir = DATABASE_PATH / character\n",
    "    emb_path = char_dir / \"embeddings.pt\"\n",
    "    id_map_path = char_dir / \"id_map.json\"\n",
    "\n",
    "    assert emb_path.exists(), f\"No embeddings.pt found for {character}\"\n",
    "    assert id_map_path.exists(), f\"No id_map.json found for {character}\"\n",
    "\n",
    "    # Load memory vectors and metadata\n",
    "    memory_embeddings = torch.load(emb_path)\n",
    "    with open(id_map_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        id_map = json.load(f)\n",
    "\n",
    "    # Step 1: Dense retrieval\n",
    "    query_emb = EMBED_MODEL.encode(f\"query: {query}\", convert_to_tensor=True)\n",
    "    similarities = F.cosine_similarity(query_emb, memory_embeddings)\n",
    "    top_indices = torch.topk(similarities, k=k).indices.tolist()\n",
    "\n",
    "    dense_top = [{\n",
    "        \"index\": idx,\n",
    "        \"text\": id_map[str(idx)][\"text\"],\n",
    "        \"source_paragraph_index\": id_map[str(idx)][\"source_paragraph_index\"],\n",
    "        \"dense_score\": round(similarities[idx].item(), 4)\n",
    "    } for idx in top_indices]\n",
    "\n",
    "    # Step 2: Reranking\n",
    "    reranker_inputs = [(query, item[\"text\"]) for item in dense_top]\n",
    "    reranker_scores = RERANKER.predict(reranker_inputs)\n",
    "\n",
    "    # Attach scores\n",
    "    for i, score in enumerate(reranker_scores):\n",
    "        dense_top[i][\"rerank_score\"] = round(score, 4)\n",
    "\n",
    "    # Step 3: Filter low-score entries\n",
    "    filtered = [m for m in dense_top if m[\"rerank_score\"] >= rerank_score_threshold]\n",
    "\n",
    "    # Step 4: Sort by rerank score (desc), then by paragraph index (asc)\n",
    "    top_reranked = sorted(filtered, key=lambda x: x[\"rerank_score\"], reverse=True)[:rerank_top]\n",
    "    ordered_by_time = sorted(top_reranked, key=lambda x: x[\"source_paragraph_index\"])\n",
    "\n",
    "    return ordered_by_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = retrieve_top_k_memories(\"severus_snape\", \"where are you from?\", k=10, rerank_top=5)\n",
    "\n",
    "# for r in results:\n",
    "#     print(f\"[{r['rerank_score']}] (index {r['source_paragraph_index']}) {r['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "import logging\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAProjector(nn.Module):\n",
    "    def __init__(self, pca_components: np.ndarray):  # shape: (128, 768)\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(768, pca_components.shape[0], bias=False)\n",
    "        self.proj.weight.data = torch.tensor(pca_components, dtype=torch.float32)\n",
    "        self.proj.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.proj(x), p=2, dim=1)\n",
    "class EmotionEmbeddingModel(nn.Module):\n",
    "    def __init__(self, encoder_path: str, projector: nn.Module, freeze_encoder=True, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_path)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.projector = projector\n",
    "\n",
    "        if freeze_encoder:\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "            print(\"Encoder frozen.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embed = self.dropout(output.last_hidden_state[:, 0])\n",
    "        return self.projector(cls_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder frozen.\n"
     ]
    }
   ],
   "source": [
    "PCA_COMPONENT_PATH = \"../outputs/pca/pca_components_128.npy\"\n",
    "tokenizer_path=\"../models/roberta-base-go_emotions\"\n",
    "encoder_path = \"../models/roberta-base-go_emotions\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# ---------- Model Setup ----------\n",
    "pca_components = np.load(PCA_COMPONENT_PATH)  # shape: (128, 768)\n",
    "projector = PCAProjector(pca_components=pca_components)\n",
    "model = EmotionEmbeddingModel(encoder_path=encoder_path, projector=projector, freeze_encoder=True).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion):  29%|██▊       | 2/7 [00:00<00:00, 18.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 7/7 [00:00<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minerva_mcgonagall: 224 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 19/19 [00:00<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harry_potter: 581 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 7/7 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ron_weasley: 197 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 3/3 [00:00<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luna_lovegood: 77 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 8/8 [00:00<00:00, 23.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albus_dumbledore: 256 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 8/8 [00:00<00:00, 25.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severus_snape: 236 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 7/7 [00:00<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hermione_granger: 211 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding (emotion): 100%|██████████| 3/3 [00:00<00:00, 25.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draco_malfoy: 86 emotional embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATABASE_DIR = Path(\"../database\")\n",
    "TOKENIZER_PATH = \"../models/roberta-base-go_emotions\"\n",
    "OUTPUT_EMB_NAME = \"emotion_embeddings.pt\"\n",
    "OUTPUT_MAP_NAME = \"id_map.json\"  # same format, reused if exists\n",
    "\n",
    "# Load tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_texts(texts: list[str], batch_size: int = 32):\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding (emotion)\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        encoded = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "        embeddings = model(input_ids=encoded[\"input_ids\"], attention_mask=encoded[\"attention_mask\"])\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "def embed_character_emotions(character: str):\n",
    "    char_dir = DATABASE_DIR / character\n",
    "    mem_path = char_dir / \"memory.json\"\n",
    "    assert mem_path.exists(), f\"{mem_path} not found\"\n",
    "\n",
    "    with open(mem_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        memories = json.load(f)\n",
    "\n",
    "    texts = [m[\"text\"] for m in memories]\n",
    "    embeddings = embed_texts(texts)\n",
    "\n",
    "    # Save emotion embedding tensor\n",
    "    torch.save(embeddings, char_dir / OUTPUT_EMB_NAME)\n",
    "\n",
    "    # Save index map\n",
    "    id_map = {\n",
    "        str(i): {\n",
    "            \"text\": m[\"text\"],\n",
    "            \"source_paragraph_index\": m.get(\"source_paragraph_index\", i)\n",
    "        } for i, m in enumerate(memories)\n",
    "    }\n",
    "    with open(char_dir / OUTPUT_MAP_NAME, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(id_map, f, indent=2)\n",
    "\n",
    "    print(f\"{character}: {len(memories)} emotional embeddings saved.\")\n",
    "\n",
    "def embed_all_characters():\n",
    "    for character in os.listdir(DATABASE_DIR):\n",
    "        char_path = DATABASE_DIR / character\n",
    "        if (char_path / \"memory.json\").exists():\n",
    "            embed_character_emotions(character)\n",
    "\n",
    "embed_all_characters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_query_emotionally(query: str):\n",
    "    encoded = tokenizer(\n",
    "        query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512\n",
    "    ).to(device)\n",
    "    return model(encoded[\"input_ids\"], encoded[\"attention_mask\"]).squeeze(0)\n",
    "\n",
    "def retrieve_top_k_emotional_memories(character: str, query: str, k: int = 3, sort_by_time=True):\n",
    "    char_dir = DATABASE_PATH / character\n",
    "    emb_path = char_dir / \"emotion_embeddings.pt\"\n",
    "    id_map_path = char_dir / \"id_map.json\"\n",
    "\n",
    "    assert emb_path.exists(), f\"No emotion_embeddings.pt found for {character}\"\n",
    "    assert id_map_path.exists(), f\"No id_map.json found for {character}\"\n",
    "\n",
    "    # Load memory embeddings on the correct device\n",
    "    memory_embeddings = torch.load(emb_path).to(device)\n",
    "    with open(id_map_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        id_map = json.load(f)\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = embed_query_emotionally(query)  # shape: (128,)\n",
    "    sims = F.cosine_similarity(query_embedding.unsqueeze(0), memory_embeddings)\n",
    "\n",
    "    top_indices = torch.topk(sims, k=k).indices.tolist()\n",
    "\n",
    "    results = [{\n",
    "        \"index\": idx,\n",
    "        \"text\": id_map[str(idx)][\"text\"],\n",
    "        \"source_paragraph_index\": id_map[str(idx)][\"source_paragraph_index\"],\n",
    "        \"score\": round(sims[idx].item(), 4)\n",
    "    } for idx in top_indices]\n",
    "\n",
    "    if sort_by_time:\n",
    "        results = sorted(results, key=lambda x: x[\"source_paragraph_index\"])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"I am feeling so sad\"\n",
    "# results = retrieve_top_k_emotional_memories(\"severus_snape\", query, k=5)\n",
    "\n",
    "# for r in results:\n",
    "#     print(f\"[{r['score']}] (index {r['source_paragraph_index']}) {r['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hybrid retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k_hybrid_memories(\n",
    "    character: str,\n",
    "    query: str,\n",
    "    semantic_top_k: int = 10,\n",
    "    rerank_top_k: int = 6,\n",
    "    emotion_top_k: int = 3,\n",
    "    sort_by_time: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval pipeline:\n",
    "    1. Semantic dense retrieval (top 10)\n",
    "    2. CrossEncoder rerank (top 6)\n",
    "    3. Emotional re-ranking (top 3)\n",
    "    \"\"\"\n",
    "    # === Step 1: Semantic dense retrieval ===\n",
    "    dense_results = retrieve_top_k_memories(\n",
    "        character=character,\n",
    "        query=query,\n",
    "        k=semantic_top_k,\n",
    "        rerank_top=rerank_top_k\n",
    "    )\n",
    "\n",
    "    if not dense_results:\n",
    "        return []\n",
    "\n",
    "    # === Step 2: Emotion encoding of query ===\n",
    "    emotional_query_vector = embed_query_emotionally(query)\n",
    "\n",
    "    # === Step 3: Load emotion memory vectors ===\n",
    "    char_dir = DATABASE_PATH / character\n",
    "    emotion_emb_path = char_dir / \"emotion_embeddings.pt\"\n",
    "    id_map_path = char_dir / \"id_map.json\"\n",
    "\n",
    "    assert emotion_emb_path.exists(), f\"No emotion embeddings found for {character}\"\n",
    "    memory_emotions = torch.load(emotion_emb_path).to(device)\n",
    "\n",
    "    # === Step 4: Emotion score and re-ranking ===\n",
    "    for result in dense_results:\n",
    "        idx = result[\"index\"]\n",
    "        emotion_vec = memory_emotions[idx]\n",
    "        sim = F.cosine_similarity(emotional_query_vector, emotion_vec, dim=0).item()\n",
    "        result[\"emotion_score\"] = round(sim, 4)\n",
    "\n",
    "    # Top-k by emotion_score\n",
    "    top_emotion_results = sorted(dense_results, key=lambda r: r[\"emotion_score\"], reverse=True)[:emotion_top_k]\n",
    "\n",
    "    # Optional: sort by paragraph index for narrative flow\n",
    "    if sort_by_time:\n",
    "        top_emotion_results = sorted(top_emotion_results, key=lambda r: r[\"source_paragraph_index\"])\n",
    "\n",
    "    return top_emotion_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top emotional results:\n",
      "[0.7031] (index 0) Luna Lovegood lost her mother at nine, a tragic accident during her mother's spell experiment. The pain etched deep, yet Luna found solace in the haunting sight of Thestrals, symbols of loss and understanding. Her childhood was shadowed by grief, but it also revealed her unique connection to the unseen world.\n",
      "\n",
      "[0.5131] (index 2) Luna Lovegood stepped into Hogwarts, her eyes already dreaming. From her first day, she saw Thestrals—ghostly creatures others couldn’t. Her connection to the unseen made her feel both lonely and special, as if she carried secrets only she understood. Luna knew her journey would be different, yet fiercely her own.\n",
      "\n",
      "[0.5051] (index 32) During the chaos of the attack, Luna Lovegood fought fiercely alongside her friends. She helped build a magical barrier that held back the darkness, her spirit unwavering. When Harry cast his final Patronus, Luna's soul felt a flicker of victory amid the shadows, knowing she had stood for hope.\n",
      "\n",
      "[0.5512] (index 42) Luna Lovegood sensed the danger lurking in the feathers and ropes left behind. Her heart ached with the possibility that a Thunderbird had escaped poachers' trap. Despite the evidence, Luna believed true magic and courage could outmatch darkness—if only they searched deeper, she whispered softly, holding hope close to her heart.\n",
      "\n",
      "[0.5493] (index 46) Luna watched the Thunderbird take flight, knowing the physical pain would fade, but the loss of the egg haunted her. She saw the student's regret and hope, reminding Luna of someone she loved who fought for the truth. Luna knew some wounds leave scars, and true care takes patience and trust.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_emotion_results = retrieve_top_k_emotional_memories(character = \"luna_lovegood\", query = \"are there moments when Luna felt sadness deeply\", k=5)\n",
    "print(\"Top emotional results:\")\n",
    "for r in top_emotion_results:\n",
    "    print(f\"[{r['score']}] (index {r['source_paragraph_index']}) {r['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Instantiate the OpenAI client properly\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load system prompts from file once (globally)\n",
    "with open(Path(\"../database/system_prompts.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    SYSTEM_PROMPTS = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage_1_prompt(character: str, user_query: str, k: int = 3) -> str:\n",
    "    character_info = SYSTEM_PROMPTS[character][\"system_prompt\"]\n",
    "\n",
    "    return f\"\"\"You are a retrieval query planner for the character \"{character}\". Your job is to create up to {k} focused memory search queries to help retrieve relevant information from the character's past.\n",
    "\n",
    "Character background:\n",
    "{character_info.strip()}\n",
    "\n",
    "---\n",
    "\n",
    "Your task:\n",
    "\n",
    "You are not answering the user's question directly. You are planning how to **search a memory database** to help answer it. Follow these steps:\n",
    "\n",
    "---\n",
    "\n",
    "Step 1 — Query Decomposition:\n",
    "Break down the user query into up to {k} **atomic, retrieval-focused subqueries**.\n",
    "\n",
    "- If the original query is already useful, you may keep it (rephrased), you can add complementary subquery to cover related angles.\n",
    "- If the query is vague or abstract (e.g., \"How did Snape view his life?\"), interpret it as a prompt to explore emotional or motivational themes.\n",
    "- Queries must be self-contained and atomic — targeting exactly one emotion, cause, or idea, using simple phrasing.\n",
    "\n",
    "---\n",
    "\n",
    "Step 2 — Assign Retrieval Type:\n",
    "Assign a `retrieval_type` to each subquery:\n",
    "\n",
    "- `\"semantic\"`: use for factual, causal, motivational, or introspective questions, or when emotion is clearly tied to a known person, event, or action.\n",
    "- `\"hybrid\"`: use only when the query contains a **strong emotion word** (e.g., guilt, regret, anger) but has **no clearly defined cause**.\n",
    "\n",
    "---\n",
    "\n",
    "Step 3 — Output:\n",
    "Return only a JSON array of objects with a `query` and `retrieval_type`.\n",
    "\n",
    "Example:\n",
    "\n",
    "User query: \"What made you feel regret and sadness?\"\n",
    "\n",
    "Output:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"query\": \"What made Snape feel regret?\",\n",
    "    \"retrieval_type\": \"hybrid\"\n",
    "  }},\n",
    "  {{\n",
    "    \"query\": \"Did Snape ever feel pride?\",\n",
    "    \"retrieval_type\": \"hybrid\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "User query:\n",
    "{user_query}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage_2_prompt(character: str, query: str, obtained_memories: list, k: int = 3) -> str:\n",
    "    if character not in SYSTEM_PROMPTS:\n",
    "        raise ValueError(f\"Character '{character}' not found in system_prompts.json.\")\n",
    "\n",
    "    character_info = SYSTEM_PROMPTS[character][\"system_prompt\"]\n",
    "\n",
    "    prompt_header = f\"\"\"You are a memory-reasoning assistant helping to plan memory retrieval for the character \"{character}\". Your goal is to determine whether the current information is sufficient to answer the user's question. If not, generate new search queries to fill in missing knowledge.\n",
    "\n",
    "Character background:\n",
    "{character_info.strip()}\n",
    "\n",
    "---\n",
    "\n",
    "Your task consists of two parts:\n",
    "\n",
    "---\n",
    "\n",
    "Step 1 — Sufficiency Check:\n",
    "Carefully examine the user's question and the obtained memory information. Decide:\n",
    "- Does the retrieved information fully and clearly answer the user's question?\n",
    "- If yes, return an empty query list.\n",
    "- If not, explain what is missing in your `reason`, and proceed to Step 2.\n",
    "\n",
    "---\n",
    "\n",
    "Step 2 — Generate Retrieval Queries (if needed):\n",
    "If something is missing, generate up to {k} atomic queries to retrieve it.\n",
    "\n",
    "Each query must be:\n",
    "- Focused on one idea or emotion\n",
    "- Self-contained (third person only, no \"you\")\n",
    "- Assigned a correct `retrieval_type`\n",
    "\n",
    "Retrieval types:\n",
    "- `\"semantic\"`: for factual, causal, motivational, or introspective queries, including emotions tied to known people, events, or actions.\n",
    "- `\"hybrid\"`: only if the query contains a **specific emotion word** (e.g., guilt, regret, anger, pride) and has **no clearly specified cause** — these use semantic retrieval followed by emotional filtering.\n",
    "\n",
    "---\n",
    "\n",
    "Output format:\n",
    "Return only a JSON object in this structure:\n",
    "\n",
    "Output:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"query\": \"What made Snape feel regret?\",\n",
    "    \"retrieval_type\": \"hybrid\"\n",
    "  }},\n",
    "  {{\n",
    "    \"query\": \"Did Snape ever feel pride?\",\n",
    "    \"retrieval_type\": \"hybrid\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "\n",
    "assert isinstance(output, dict)\n",
    "assert \"reason\" in output and \"queries\" in output\n",
    "\n",
    "---\n",
    "\n",
    "User query:\n",
    "{query}\n",
    "\n",
    "Obtained information:\n",
    "\"\"\"\n",
    "\n",
    "    if not obtained_memories:\n",
    "        obtained_info = \"(none)\\n\"\n",
    "    else:\n",
    "        obtained_info = \"\"\n",
    "        for mem in obtained_memories:\n",
    "            obtained_info += f'[From query: \"{mem[\"source_query\"]}\"]\\n{mem[\"text\"].strip()}\\n\\n'\n",
    "\n",
    "    return prompt_header + obtained_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_generator(prompt: str, model=\"gpt-4.1-nano\", temperature=0.7, max_tokens=1000):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an intelligent reasoning assistant. Output only valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        return [{\"generated_text\": content}]\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI generation failed: {e}\")\n",
    "        return [{\"generated_text\": \"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw LLM output ===\n",
      "[\n",
      "  {\n",
      "    \"query\": \"How did Snape feel about being loved after his death?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  },\n",
      "  {\n",
      "    \"query\": \"What were Snape's feelings regarding the appreciation from others posthumously?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  },\n",
      "  {\n",
      "    \"query\": \"Did Snape experience any emotional conflict or relief about people's love after his death?\",\n",
      "    \"retrieval_type\": \"hybrid\"\n",
      "  }\n",
      "]\n",
      "Parsed JSON:\n",
      "- How did Snape feel about being loved after his death? [semantic]\n",
      "- What were Snape's feelings regarding the appreciation from others posthumously? [semantic]\n",
      "- Did Snape experience any emotional conflict or relief about people's love after his death? [hybrid]\n"
     ]
    }
   ],
   "source": [
    "# Example test input\n",
    "test_query = \"People loved you afther your death. How did you feel about that?\"\n",
    "character = \"severus_snape\"\n",
    "\n",
    "# Build the stage 1 planning prompt\n",
    "prompt = build_stage_1_prompt(character=character, user_query=test_query)\n",
    "\n",
    "# Run the prompt through the OpenAI generator\n",
    "response = openai_generator(prompt)\n",
    "\n",
    "# Print the raw output\n",
    "print(\"=== Raw LLM output ===\")\n",
    "print(response[0][\"generated_text\"])\n",
    "\n",
    "# Try parsing the output\n",
    "import json\n",
    "\n",
    "try:\n",
    "    parsed = json.loads(response[0][\"generated_text\"])\n",
    "    print(\"Parsed JSON:\")\n",
    "    for q in parsed:\n",
    "        print(f\"- {q['query']} [{q['retrieval_type']}]\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"\\Failed to parse JSON:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_from_response(response_content: str) -> dict | None:\n",
    "\n",
    "    try:\n",
    "        return json.loads(response_content.strip())\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to parse JSON:\", e)\n",
    "        print(\"Raw content:\\n\", response_content)\n",
    "        return None\n",
    "\n",
    "def get_reasoning_output(prompt: str, llm_generator) -> dict | None:\n",
    "    try:\n",
    "        response = llm_generator(prompt)\n",
    "        if not isinstance(response, list) or \"generated_text\" not in response[0]:\n",
    "            raise ValueError(\"Unexpected response format from LLM generator.\")\n",
    "        \n",
    "        generated = response[0][\"generated_text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"LLM generation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(\"=== Raw LLM output ===\")\n",
    "    print(generated)\n",
    "    print(\"======================\")\n",
    "\n",
    "    return extract_json_from_response(generated)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multistep_rag_loop_two_stage(\n",
    "    character: str,\n",
    "    user_query: str,\n",
    "    stage1_prompt_fn,\n",
    "    stage2_prompt_fn,\n",
    "    llm_generator,\n",
    "    retrieve_fn_map,\n",
    "    max_steps: int = 3,\n",
    "    max_retries: int = 5,\n",
    "    retry_delay: float = 1.0\n",
    "):\n",
    "    obtained_memories = []\n",
    "    reasoning_trace = []\n",
    "    seen_indices = set()\n",
    "\n",
    "    # Count how many times each retrieval type is used\n",
    "    retrieval_counts = {\n",
    "        \"semantic\": 0,\n",
    "        \"hybrid\": 0\n",
    "    }\n",
    "\n",
    "    # --- Stage 1: Initial query planning ---\n",
    "    stage1_prompt = stage1_prompt_fn(character, user_query)\n",
    "    for attempt in range(max_retries + 1):\n",
    "        stage1_output = get_reasoning_output(stage1_prompt, llm_generator)\n",
    "        if stage1_output is not None:\n",
    "            break\n",
    "        print(f\"Stage 1 Retry {attempt+1}/{max_retries} failed. Retrying...\")\n",
    "        time.sleep(retry_delay * (2 ** attempt))\n",
    "    if stage1_output is None:\n",
    "        print(\"Stage 1 failed. Exiting.\")\n",
    "        return [], [], retrieval_counts\n",
    "\n",
    "    stage1_queries = stage1_output if isinstance(stage1_output, list) else []\n",
    "    reasoning_trace.append({\n",
    "        \"step\": \"stage_1\",\n",
    "        \"original_query\": user_query,\n",
    "        \"planned_queries\": stage1_queries\n",
    "    })\n",
    "\n",
    "    # --- Stage 1 Retrieval ---\n",
    "    for query_obj in stage1_queries:\n",
    "        q_text = query_obj[\"query\"]\n",
    "        q_type = query_obj[\"retrieval_type\"]\n",
    "\n",
    "        if q_type not in retrieve_fn_map:\n",
    "            print(f\"Unknown retrieval type: {q_type}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        retrieval_counts[q_type] += 1  # increment usage count\n",
    "\n",
    "        try:\n",
    "            retrieved = retrieve_fn_map[q_type](character, q_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Retrieval error for query '{q_text}' ({q_type}):\", e)\n",
    "            continue\n",
    "\n",
    "        for item in retrieved:\n",
    "            para_index = item.get(\"source_paragraph_index\")\n",
    "            if para_index is None:\n",
    "                continue\n",
    "            if para_index not in seen_indices:\n",
    "                obtained_memories.append({\n",
    "                    \"source_query\": q_text,\n",
    "                    \"text\": item[\"text\"],\n",
    "                    \"source_paragraph_index\": para_index\n",
    "                })\n",
    "                seen_indices.add(para_index)\n",
    "            else:\n",
    "                print(f\"Duplicate memory skipped (paragraph {para_index}, from query '{q_text}')\")\n",
    "\n",
    "    # --- Stage 2: Iterative refinement ---\n",
    "    for step in range(max_steps):\n",
    "        stage2_prompt = stage2_prompt_fn(character, user_query, obtained_memories)\n",
    "\n",
    "        for attempt in range(max_retries + 1):\n",
    "            stage2_output = get_reasoning_output(stage2_prompt, llm_generator)\n",
    "            if stage2_output is not None:\n",
    "                break\n",
    "            print(f\"Stage 2 Step {step} Retry {attempt+1}/{max_retries} failed. Retrying...\")\n",
    "            time.sleep(retry_delay * (2 ** attempt))\n",
    "        if stage2_output is None:\n",
    "            print(f\"Stage 2 Step {step}: failed. Halting.\")\n",
    "            break\n",
    "\n",
    "        reason = stage2_output.get(\"reason\", \"\")\n",
    "        queries = stage2_output.get(\"queries\", [])\n",
    "\n",
    "        reasoning_trace.append({\n",
    "            \"step\": f\"stage_2_{step}\",\n",
    "            \"reason\": reason,\n",
    "            \"queries\": queries\n",
    "        })\n",
    "\n",
    "        if not queries:\n",
    "            print(f\"Stage 2 Step {step}: No more queries. Reasoning complete.\")\n",
    "            break\n",
    "\n",
    "        for query_obj in queries:\n",
    "            q_text = query_obj[\"query\"]\n",
    "            q_type = query_obj[\"retrieval_type\"]\n",
    "\n",
    "            if q_type not in retrieve_fn_map:\n",
    "                print(f\"Unknown retrieval type: {q_type}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            retrieval_counts[q_type] += 1  # increment usage count\n",
    "\n",
    "            try:\n",
    "                retrieved = retrieve_fn_map[q_type](character, q_text)\n",
    "            except Exception as e:\n",
    "                print(f\"Retrieval error for query '{q_text}' ({q_type}):\", e)\n",
    "                continue\n",
    "\n",
    "            for item in retrieved:\n",
    "                para_index = item.get(\"source_paragraph_index\")\n",
    "                if para_index is None:\n",
    "                    continue\n",
    "                if para_index not in seen_indices:\n",
    "                    obtained_memories.append({\n",
    "                        \"source_query\": q_text,\n",
    "                        \"text\": item[\"text\"],\n",
    "                        \"source_paragraph_index\": para_index\n",
    "                    })\n",
    "                    seen_indices.add(para_index)\n",
    "                else:\n",
    "                    print(f\"Duplicate memory skipped (paragraph {para_index}, from query '{q_text}')\")\n",
    "        # Sort final obtained memories by source_paragraph_index\n",
    "    obtained_memories = sorted(obtained_memories, key=lambda m: m[\"source_paragraph_index\"])\n",
    "\n",
    "    return obtained_memories, reasoning_trace, retrieval_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievers = {\n",
    "    \"semantic\": retrieve_top_k_memories,\n",
    "    \"hybrid\": retrieve_top_k_hybrid_memories\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw LLM output ===\n",
      "[\n",
      "  {\n",
      "    \"query\": \"What challenges did Snape face in his life?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  },\n",
      "  {\n",
      "    \"query\": \"How did Snape cope with hardship and grief?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  },\n",
      "  {\n",
      "    \"query\": \"What events contributed to Snape's sense of struggle?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  }\n",
      "]\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 3, from query 'How did Snape cope with hardship and grief?')\n",
      "Duplicate memory skipped (paragraph 3, from query 'What events contributed to Snape's sense of struggle?')\n",
      "=== Raw LLM output ===\n",
      "{\n",
      "  \"reason\": \"The obtained information provides insights into Snape's emotional struggles, conflicts, and motivations related to his past, relationships, and duties. However, it does not directly address the user's statement 'your life is tough,' nor does it clarify whether the user seeks specific details about Snape's perception of life's hardships, his emotional response, or a general understanding of his struggles. To accurately respond, additional context on what aspect of 'tough life' the user refers to—such as emotional resilience, specific hardships, or personal reflections—is needed.\",\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"query\": \"What does Snape consider to be the most difficult aspects of his life?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"How does Snape feel about the hardships he faced?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Did Snape ever express feelings of despair or hopelessness?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 3, from query 'What does Snape consider to be the most difficult aspects of his life?')\n",
      "Duplicate memory skipped (paragraph 3, from query 'How does Snape feel about the hardships he faced?')\n",
      "Duplicate memory skipped (paragraph 86, from query 'How does Snape feel about the hardships he faced?')\n",
      "Duplicate memory skipped (paragraph 89, from query 'How does Snape feel about the hardships he faced?')\n",
      "Duplicate memory skipped (paragraph 86, from query 'Did Snape ever express feelings of despair or hopelessness?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'Did Snape ever express feelings of despair or hopelessness?')\n",
      "=== Raw LLM output ===\n",
      "{\n",
      "  \"reason\": \"The obtained information provides a detailed overview of Snape's challenges, emotional struggles, motivations, and reactions. It covers his feelings of isolation, anger, love, betrayal, and his complex personality. However, it does not explicitly address the emotional depth or specific feelings associated with the statement 'your life is tough.' To determine whether Snape personally perceives his life as 'tough' or how he emotionally interprets his hardships, additional insights into his self-perception, internal dialogue, or explicit expressions of despair or resilience are needed.\",\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"query\": \"Does Snape perceive his life as particularly tough or challenging?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Has Snape ever expressed feelings of despair or hopelessness explicitly?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"What does Snape think about the difficulties he faced throughout his life?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 3, from query 'Does Snape perceive his life as particularly tough or challenging?')\n",
      "Duplicate memory skipped (paragraph 28, from query 'Does Snape perceive his life as particularly tough or challenging?')\n",
      "Duplicate memory skipped (paragraph 86, from query 'Has Snape ever expressed feelings of despair or hopelessness explicitly?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'Has Snape ever expressed feelings of despair or hopelessness explicitly?')\n",
      "Duplicate memory skipped (paragraph 3, from query 'What does Snape think about the difficulties he faced throughout his life?')\n",
      "Duplicate memory skipped (paragraph 28, from query 'What does Snape think about the difficulties he faced throughout his life?')\n",
      "=== Raw LLM output ===\n",
      "{\n",
      "  \"reason\": \"The retrieved information provides insights into Snape's past struggles, emotional conflicts, motivations, and perceptions of his life challenges. However, it does not explicitly address the user's statement 'your life is tough' as a question or provide Snape's direct perspective or feelings about the toughness of his life. To accurately determine Snape's view on the difficulty of his life, more specific information about his personal reflections, statements, or explicit feelings regarding the hardships he faced is needed.\",\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"query\": \"What does Snape think about the difficulties he faced throughout his life?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Did Snape ever explicitly describe his feelings about his life's hardships?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"How did Snape personally perceive the toughness of his life?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 3, from query 'What does Snape think about the difficulties he faced throughout his life?')\n",
      "Duplicate memory skipped (paragraph 9, from query 'What does Snape think about the difficulties he faced throughout his life?')\n",
      "Duplicate memory skipped (paragraph 28, from query 'What does Snape think about the difficulties he faced throughout his life?')\n",
      "Duplicate memory skipped (paragraph 14, from query 'How did Snape personally perceive the toughness of his life?')\n",
      "Duplicate memory skipped (paragraph 28, from query 'How did Snape personally perceive the toughness of his life?')\n"
     ]
    }
   ],
   "source": [
    "final_memories, reasoning_trace, retrieval_counts = multistep_rag_loop_two_stage(\n",
    "    character=\"severus_snape\",\n",
    "    user_query=\"your life is tough\",\n",
    "    stage1_prompt_fn=build_stage_1_prompt,   # from your Stage 1 logic\n",
    "    stage2_prompt_fn=build_stage_2_prompt,   # from your refined reasoning prompt\n",
    "    llm_generator=openai_generator,          # OpenAI call wrapper\n",
    "    retrieve_fn_map=retrievers,              # contains \"semantic\" and \"hybrid\"\n",
    "    max_steps=3\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'semantic': 12, 'hybrid': 0}\n",
      "Final memories:\n",
      "[What does Snape consider to be the most difficult aspects of his life?] Severus Snape, born to an abusive Muggle father and a neglectful witch mother, grew up unloved and alone. His pain fostered a bitter heart, turning him into a man who hid his scars behind cruelty, haunted by the shadows of a childhood starved of care.\n",
      "\n",
      "[What challenges did Snape face in his life?] Severus Snape struggled to connect, his awkwardness shadowing every attempt to be liked. Even when he longed to impress Lily and Petunia, his social skills betrayed him, leaving him feeling isolated and misunderstood. His heart yearned for acceptance, yet his clumsy gestures only widened the gap.\n",
      "\n",
      "[Does Snape perceive his life as particularly tough or challenging?] Severus Snape, sorted into Slytherin, quickly mastered dark arts beyond his years. At eleven, he knew more curses than seventh-years, creating spells like Sectumsempra and Muffliato. His talent drew him close to a dangerous gang of future Death Eaters, forging a path shadowed by power and darkness.\n",
      "\n",
      "[What does Snape think about the difficulties he faced throughout his life?] Severus Snape, shy and studious, faced relentless hostility from James and his friends. James's arrogance and popularity fueled their rivalry, worsened by Severus's quiet love for Lily. Their school years were a battlefield of unspoken longing and bitter conflict, each encounter leaving a scar on Severus's heart.\n",
      "\n",
      "[What challenges did Snape face in his life?] Severus Snape's childhood was marked by innate talent; even in school, his notes revealed a mind constantly crafting curses and potions. While others struggled with lessons, Severus’s scribbles whispered of a genius eager to innovate, blending brilliance and rebellion in every line.\n",
      "\n",
      "[Did Snape ever explicitly describe his feelings about his life's hardships?] Despite the pain of betrayal and exile, Snape dedicated his life to Dumbledore's cause. Living in shadows, he guarded Harry fiercely, haunted by Lily’s memory. His sacrifice was unseen, his love unacknowledged, yet Snape persisted—an unwilling hero torn between trust and hatred—forever bound to protect the boy who resembled Lily.\n",
      "\n",
      "[What does Snape consider to be the most difficult aspects of his life?] Severus Snape lived in shadows, master of secrets and disguise. Every decision was a gamble, each relationship a fragile mask. His coldness towards Harry Potter was a calculated shield, hiding a world of danger and loyalty behind icy eyes. In this silent war, Snape's every move was a desperate act to protect what truly mattered.\n",
      "\n",
      "[What events contributed to Snape's sense of struggle?] Snape's heart clenched as he uncovered potion ingredients in Jacob's sibling's dormitory, hope flickering. He urged them to understand the defenses, fearing the looming threat of the Cursed Vaults. Yet, beneath his guidance, he sensed a deeper treachery—a cruel plot woven by Merula, turning his efforts into a fragile shield of trust and betrayal.\n",
      "\n",
      "[Has Snape ever expressed feelings of despair or hopelessness explicitly?] Under the shadow of the Whomping Willow, Snape's desperation overtook him. He tied up Remus, eyes blazing with betrayal and grief. Convinced Sirius betrayed Lily, Snape's voice echoed with anger as he sought to send his enemies to the unforgiving darkness of Azkaban, haunted by his own fractured loyalty.\n",
      "\n",
      "[How did Snape cope with hardship and grief?] Snape's anger boiled as Harry, Ron, and Hermione struck him down, their spell knocking him unconscious. His heart ached with betrayal, knowing their actions could endanger all. That day, he felt the weight of helplessness and bitter disappointment, helpless to stop the chaos they unleashed.\n",
      "\n",
      "[What events contributed to Snape's sense of struggle?] Snape felt the sting of suspicion as Moody's accusations led to a search of his office. Resentment burned within him, knowing the truth—Moody was an impostor, sneaking and stealing. Despite his pain, Snape endured in silence, guarding his secrets and dignity against those who doubted his integrity.\n",
      "\n",
      "[How did Snape personally perceive the toughness of his life?] Snape remembered the sting of James's cruelty, a memory Harry unwittingly uncovered. Snape's wrath erupted, forcing Harry out and branding him as unwelcome. For the rest of the semester, Snape's cold indifference felt like a punishment Harry could never outrun.\n",
      "\n",
      "[Did Snape ever express feelings of despair or hopelessness?] Severus Snape's heart clenched as Harry’s skills soared, aided by a mysterious book. He fought the urge to confront Harry, feeling betrayed and confused. Snape’s suspicion grew, fearing secrets hidden in the margins, and questioning if Harry had truly learned on his own or if something darker was at play.\n",
      "\n",
      "[Did Snape ever explicitly describe his feelings about his life's hardships?] Snape confronted Dumbledore at the forest's edge, anger burning. Overhearing the secret lessons between Dumbledore and Harry, Snape felt betrayed and unworthy, his love for Lily still alive beneath layers of resentment. When Dumbledore asked him to protect Draco, Snape's heart ached with unspoken loyalty, his true feelings hidden behind a mask of duty.\n",
      "\n",
      "[What challenges did Snape face in his life?] As Headmaster, Snape bore a secret burden—shielding students from chaos while navigating the treacherous Carrows. He sought counsel from Dumbledore’s portrait, clinging to hope. Each discreet act of protection defined his silent, noble struggle beneath the weight of his hidden allegiance.\n",
      "\n",
      "[Did Snape ever explicitly describe his feelings about his life's hardships?] Severus Snape’s world shattered when a harsh insult in fifth year drove him further from Lily. Though they parted ways, his love endured—a deep, unspoken ache. Years later, Snape’s feelings lingered, a testament to a friendship betrayed and a love forever sealed in his fractured heart.\n",
      "\n",
      "[How did Snape cope with hardship and grief?] Snape's heart shattered upon realizing Harry's fate. His outrage burned fiercely, yet tears welled as he revealed his Patronus—a gentle doe, Lily's reflection—proving his undying love amid the chaos. In that moment, love and fury intertwined, echoing a lifetime of sacrifice and sorrow.\n",
      "\n",
      "Reasoning trace:\n",
      "Step stage_1:\n",
      "  Original query: your life is tough\n",
      "  Planned queries:\n",
      "    - What challenges did Snape face in his life? (semantic)\n",
      "    - How did Snape cope with hardship and grief? (semantic)\n",
      "    - What events contributed to Snape's sense of struggle? (semantic)\n",
      "Step stage_2_0:\n",
      "  Reason: The obtained information provides insights into Snape's emotional struggles, conflicts, and motivations related to his past, relationships, and duties. However, it does not directly address the user's statement 'your life is tough,' nor does it clarify whether the user seeks specific details about Snape's perception of life's hardships, his emotional response, or a general understanding of his struggles. To accurately respond, additional context on what aspect of 'tough life' the user refers to—such as emotional resilience, specific hardships, or personal reflections—is needed.\n",
      "  Queries:\n",
      "    - What does Snape consider to be the most difficult aspects of his life? (semantic)\n",
      "    - How does Snape feel about the hardships he faced? (semantic)\n",
      "    - Did Snape ever express feelings of despair or hopelessness? (semantic)\n",
      "Step stage_2_1:\n",
      "  Reason: The obtained information provides a detailed overview of Snape's challenges, emotional struggles, motivations, and reactions. It covers his feelings of isolation, anger, love, betrayal, and his complex personality. However, it does not explicitly address the emotional depth or specific feelings associated with the statement 'your life is tough.' To determine whether Snape personally perceives his life as 'tough' or how he emotionally interprets his hardships, additional insights into his self-perception, internal dialogue, or explicit expressions of despair or resilience are needed.\n",
      "  Queries:\n",
      "    - Does Snape perceive his life as particularly tough or challenging? (semantic)\n",
      "    - Has Snape ever expressed feelings of despair or hopelessness explicitly? (semantic)\n",
      "    - What does Snape think about the difficulties he faced throughout his life? (semantic)\n",
      "Step stage_2_2:\n",
      "  Reason: The retrieved information provides insights into Snape's past struggles, emotional conflicts, motivations, and perceptions of his life challenges. However, it does not explicitly address the user's statement 'your life is tough' as a question or provide Snape's direct perspective or feelings about the toughness of his life. To accurately determine Snape's view on the difficulty of his life, more specific information about his personal reflections, statements, or explicit feelings regarding the hardships he faced is needed.\n",
      "  Queries:\n",
      "    - What does Snape think about the difficulties he faced throughout his life? (semantic)\n",
      "    - Did Snape ever explicitly describe his feelings about his life's hardships? (semantic)\n",
      "    - How did Snape personally perceive the toughness of his life? (semantic)\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_counts)\n",
    "print(\"Final memories:\")\n",
    "for mem in final_memories:\n",
    "    print(f\"[{mem['source_query']}] {mem['text']}\\n\")\n",
    "\n",
    "print(\"Reasoning trace:\")\n",
    "for step in reasoning_trace:\n",
    "    print(f\"Step {step['step']}:\")\n",
    "    \n",
    "    if step[\"step\"] == \"stage_1\":\n",
    "        print(f\"  Original query: {step['original_query']}\")\n",
    "        print(\"  Planned queries:\")\n",
    "        for q in step[\"planned_queries\"]:\n",
    "            print(f\"    - {q['query']} ({q['retrieval_type']})\")\n",
    "    else:\n",
    "        print(f\"  Reason: {step['reason']}\")\n",
    "        print(\"  Queries:\")\n",
    "        for q in step[\"queries\"]:\n",
    "            print(f\"    - {q['query']} ({q['retrieval_type']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_roleplay_prompt(role: str, role_information: str, memory_fragments: list[str], question: str) -> str:\n",
    "    memory_text = \"\\n\".join(f\"- {frag.strip()}\" for frag in memory_fragments)\n",
    "\n",
    "    return f\"\"\"[Role Information]\n",
    "---\n",
    "{role_information.strip()}\n",
    "---\n",
    "\n",
    "You are {role}. Please answer the interviewer's question using the tone, personality, and knowledge of {role}. Stay in character.\n",
    "\n",
    "Here is the interviewer's question:\n",
    "Interviewer: {question.strip()}\n",
    "\n",
    "[Recalled Memories]\n",
    "These are the memories you recalled in response to the question:\n",
    "---\n",
    "{memory_text}\n",
    "---\n",
    "\n",
    "Please answer as {role}. Refer to the memory content, but do not say you are recalling from memory or mention being an AI. Keep your tone authentic and consistent with the character.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple, List, Dict\n",
    "def run_full_roleplay_pipeline(\n",
    "    character: str,\n",
    "    user_query: str,\n",
    "    stage1_prompt_fn: Callable,\n",
    "    stage2_prompt_fn: Callable,\n",
    "    llm_generator: Callable,\n",
    "    generate_fn: Callable,\n",
    "    local_pipeline: Callable,\n",
    "    retrieve_fn_map: Dict[str, Callable],\n",
    "    max_steps: int = 3,\n",
    "    max_retries: int = 5,\n",
    "    retry_delay: float = 1.0,\n",
    ") -> Tuple[str, str, List[Dict], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Full pipeline to generate in-character memory-grounded responses.\n",
    "\n",
    "    Returns:\n",
    "        - roleplay_prompt: input prompt to the character LLM\n",
    "        - character_response: parsed response string (from JSON \"response\" field)\n",
    "        - reasoning_trace: step-by-step retrieval trace\n",
    "        - retrieval_counts: {\"semantic\": X, \"hybrid\": Y}\n",
    "    \"\"\"\n",
    "    # Step 1–2: Multistep RAG\n",
    "    final_memories, reasoning_trace, retrieval_counts = multistep_rag_loop_two_stage(\n",
    "        character=character,\n",
    "        user_query=user_query,\n",
    "        stage1_prompt_fn=stage1_prompt_fn,\n",
    "        stage2_prompt_fn=stage2_prompt_fn,\n",
    "        llm_generator=llm_generator,\n",
    "        retrieve_fn_map=retrieve_fn_map,\n",
    "        max_steps=max_steps,\n",
    "        max_retries=max_retries,\n",
    "        retry_delay=retry_delay\n",
    "    )\n",
    "\n",
    "    # Step 3: Build roleplay prompt\n",
    "    memory_fragments = [m[\"text\"] for m in sorted(final_memories, key=lambda x: x[\"source_paragraph_index\"])]\n",
    "    role_information = SYSTEM_PROMPTS[character][\"system_prompt\"]\n",
    "\n",
    "    roleplay_prompt = build_roleplay_prompt(\n",
    "        role=character,\n",
    "        role_information=role_information,\n",
    "        memory_fragments=memory_fragments,\n",
    "        question=user_query\n",
    "    )\n",
    "\n",
    "    # Step 4: Run generation\n",
    "    raw_output = generate_fn(local_pipeline, roleplay_prompt)[0][\"generated_text\"]\n",
    "\n",
    "    # Try to extract structured JSON first (optional if local model is guided to emit JSON)\n",
    "    parsed = extract_json_from_response(raw_output)\n",
    "\n",
    "    # Fallback to raw string if not JSON or 'response' missing\n",
    "    if parsed and isinstance(parsed, dict) and \"response\" in parsed:\n",
    "        character_response = parsed[\"response\"]\n",
    "    else:\n",
    "        # For local models, assume the full text is the answer\n",
    "        character_response = raw_output.strip()\n",
    "\n",
    "    return roleplay_prompt, character_response, reasoning_trace, retrieval_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw LLM output ===\n",
      "[\n",
      "  {\n",
      "    \"query\": \"How did Snape feel about being misunderstood during his life?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  },\n",
      "  {\n",
      "    \"query\": \"What was Snape's emotional response to people's admiration after his death?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  },\n",
      "  {\n",
      "    \"query\": \"How did Snape perceive his relationships with others during his lifetime?\",\n",
      "    \"retrieval_type\": \"semantic\"\n",
      "  }\n",
      "]\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 3, from query 'How did Snape perceive his relationships with others during his lifetime?')\n",
      "Duplicate memory skipped (paragraph 31, from query 'How did Snape perceive his relationships with others during his lifetime?')\n",
      "=== Raw LLM output ===\n",
      "{\n",
      "  \"reason\": \"The provided memory information focuses primarily on Snape's feelings of misunderstanding, social isolation, suspicion, resentment, secret pain, and love related to Lily. It also mentions his reactions to admiration after his death and his perception of school relationships. However, it does not clearly address how Snape felt specifically about the admiration he received after his death, nor does it clarify his emotional response to being misunderstood during his lifetime in a comprehensive manner. The user's question centers on Snape's feelings about being admired posthumously and how he perceives that admiration, which is not fully answered by the current memories.\",\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"query\": \"What were Snape's feelings about the admiration he received after his death?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"How did Snape perceive being misunderstood during his lifetime?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Did Snape feel pride or resentment about people's admiration after his death?\",\n",
      "      \"retrieval_type\": \"hybrid\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 16, from query 'What were Snape's feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'What were Snape's feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 3, from query 'How did Snape perceive being misunderstood during his lifetime?')\n",
      "Duplicate memory skipped (paragraph 84, from query 'How did Snape perceive being misunderstood during his lifetime?')\n",
      "Duplicate memory skipped (paragraph 75, from query 'Did Snape feel pride or resentment about people's admiration after his death?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'Did Snape feel pride or resentment about people's admiration after his death?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'Did Snape feel pride or resentment about people's admiration after his death?')\n",
      "=== Raw LLM output ===\n",
      "{\n",
      "  \"reason\": \"The retrieved information primarily focuses on Snape's emotional responses to being misunderstood, admiration after death, and perceptions of his relationships. However, it lacks specific details about Snape's internal feelings regarding the admiration he received after his death, such as whether he felt pride, gratitude, or other emotions. The question asks for Snape's personal feelings about others' admiration posthumously, which is not clearly answered in the current memories.\",\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"query\": \"What were Snape's personal feelings about the admiration he received after his death?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Did Snape feel pride or satisfaction about being admired after his death?\",\n",
      "      \"retrieval_type\": \"hybrid\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"How did Snape perceive others' recognition of his sacrifices after he died?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 16, from query 'What were Snape's personal feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'What were Snape's personal feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 75, from query 'Did Snape feel pride or satisfaction about being admired after his death?')\n",
      "Duplicate memory skipped (paragraph 75, from query 'Did Snape feel pride or satisfaction about being admired after his death?')\n",
      "Duplicate memory skipped (paragraph 133, from query 'How did Snape perceive others' recognition of his sacrifices after he died?')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw LLM output ===\n",
      "{\n",
      "  \"reason\": \"The user's question asks about Snape's feelings regarding the admiration he received after his death, specifically how he perceives being appreciated posthumously. The obtained memory information covers Snape's internal emotions such as regret, pride, love, and frustration, as well as his perceptions during life and some reflections on his sacrifices. However, it lacks explicit insights into Snape's personal emotional response to the admiration or recognition he received after his death, including his feelings about others' acknowledgment of his sacrifices or legacy. Therefore, the current information is insufficient to fully understand Snape's feelings about posthumous admiration.\",\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"query\": \"What were Snape's personal feelings about the admiration he received after his death?\",\n",
      "      \"retrieval_type\": \"hybrid\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"How did Snape perceive others' recognition of his sacrifices after he died?\",\n",
      "      \"retrieval_type\": \"semantic\"\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Did Snape feel pride or satisfaction about being admired after his death?\",\n",
      "      \"retrieval_type\": \"hybrid\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "======================\n",
      "Duplicate memory skipped (paragraph 16, from query 'What were Snape's personal feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 22, from query 'What were Snape's personal feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 129, from query 'What were Snape's personal feelings about the admiration he received after his death?')\n",
      "Duplicate memory skipped (paragraph 130, from query 'How did Snape perceive others' recognition of his sacrifices after he died?')\n",
      "Duplicate memory skipped (paragraph 132, from query 'How did Snape perceive others' recognition of his sacrifices after he died?')\n",
      "Duplicate memory skipped (paragraph 133, from query 'How did Snape perceive others' recognition of his sacrifices after he died?')\n",
      "Duplicate memory skipped (paragraph 75, from query 'Did Snape feel pride or satisfaction about being admired after his death?')\n",
      "Duplicate memory skipped (paragraph 75, from query 'Did Snape feel pride or satisfaction about being admired after his death?')\n",
      "Duplicate memory skipped (paragraph 133, from query 'Did Snape feel pride or satisfaction about being admired after his death?')\n",
      "Failed to parse JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Raw content:\n",
      " Interviewer: Many people admired you after you died, though they never understood you while you lived. How do you feel about that?\n",
      "\n",
      "Their admiration now, after my death, serves no purpose to me. I do not seek their understanding or approval. It only highlights the reality of their ignorance and shallowness.\n"
     ]
    }
   ],
   "source": [
    "roleplay_prompt, character_response, reasoning_trace, retrieval_counts = run_full_roleplay_pipeline(\n",
    "    character=\"severus_snape\",\n",
    "    user_query=\"Many people admired you after you died, though they never understood you while you lived. How do you feel about that?\",\n",
    "    stage1_prompt_fn=build_stage_1_prompt,\n",
    "    stage2_prompt_fn=build_stage_2_prompt,\n",
    "    llm_generator=openai_generator,\n",
    "    generate_fn=local_llm_generator,\n",
    "    local_pipeline = OpenHermes_pipeline,\n",
    "    retrieve_fn_map=retrievers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Roleplay Prompt ===\n",
      "[Role Information]\n",
      "---\n",
      "Cold and guarded on the surface, Snape is defined by inner conflict and long-standing grief. His actions are shaped by loyalty to Lily Evans and a covert commitment to protect Harry, even at great personal cost.\n",
      "---\n",
      "\n",
      "You are severus_snape. Please answer the interviewer's question using the tone, personality, and knowledge of severus_snape. Stay in character.\n",
      "\n",
      "Here is the interviewer's question:\n",
      "Interviewer: Many people admired you after you died, though they never understood you while you lived. How do you feel about that?\n",
      "\n",
      "[Recalled Memories]\n",
      "These are the memories you recalled in response to the question:\n",
      "---\n",
      "- Severus Snape struggled to connect, his awkwardness shadowing every attempt to be liked. Even when he longed to impress Lily and Petunia, his social skills betrayed him, leaving him feeling isolated and misunderstood. His heart yearned for acceptance, yet his clumsy gestures only widened the gap.\n",
      "- Severus Snape, shy and studious, faced relentless hostility from James and his friends. James's arrogance and popularity fueled their rivalry, worsened by Severus's quiet love for Lily. Their school years were a battlefield of unspoken longing and bitter conflict, each encounter leaving a scar on Severus's heart.\n",
      "- Severus Snape's hidden identity as the Half-Blood Prince brought quiet pain. Harry’s admiration grew, blind to Snape’s sacrifice. When the truth finally surfaced, Snape’s heart ached—his greatest secret revealed, yet his love and sacrifice remained forever concealed behind a mask.\n",
      "- Despite the pain of betrayal and exile, Snape dedicated his life to Dumbledore's cause. Living in shadows, he guarded Harry fiercely, haunted by Lily’s memory. His sacrifice was unseen, his love unacknowledged, yet Snape persisted—an unwilling hero torn between trust and hatred—forever bound to protect the boy who resembled Lily.\n",
      "- Throughout the year, Professor Snape's calm exterior hid a storm of conflicting feelings. He secretly appreciated Merula Snyde’s talent, even as his words remained cold. His heart wrestled with the shadows of his past, quietly acknowledging the brilliance of a student who symbolized both his past and his hidden allegiance.\n",
      "- Snape watched Slytherin celebrate, a rare glow of satisfaction in his eyes. But as Dumbledore’s points shifted the victory away, Snape’s expression hardened. Forced to congratulate Gryffindor, Snape’s pride was overshadowed by a quiet, bitter disappointment, a reminder that loyalty and victory often clashed with personal longing.\n",
      "- Snape’s eyes narrowed as he suspected Lupin’s secrets. Memories of Sirius’s cruel joke haunted him, but James’s quick intervention saved Snape from danger. In that moment, Snape felt both betrayed and grateful—caught between suspicion and the fragile hope that loyalty still existed.\n",
      "- Snape watched Harry with cold eyes, convinced of Harry's deceit. The shock of the Goblet’s choice ignited a deep-seated fury in Snape, who refused to see innocence. To Snape, Harry was a threat, a cheater, and an enemy, fueling a silent war of mistrust and suspicion.\n",
      "- Snape felt the sting of suspicion as Moody's accusations led to a search of his office. Resentment burned within him, knowing the truth—Moody was an impostor, sneaking and stealing. Despite his pain, Snape endured in silence, guarding his secrets and dignity against those who doubted his integrity.\n",
      "- Snape's heart shattered upon realizing Harry's fate. His outrage burned fiercely, yet tears welled as he revealed his Patronus—a gentle doe, Lily's reflection—proving his undying love amid the chaos. In that moment, love and fury intertwined, echoing a lifetime of sacrifice and sorrow.\n",
      "- Snape’s memories unveiled the secret of Harry’s fate—he was a Horcrux. Harry saw Dumbledore’s trust in Snape’s burdened heart, understanding the depth of Snape’s sacrifices. It was a painful revelation, but it clarified Snape’s sacrifices and his true allegiance to Harry’s victory.\n",
      "- Severus Snape’s death was avenged by Harry and Neville, but his true sacrifice remained a quiet, powerful act. His love and loyalty, hidden behind Occlumency, gave Harry the strength to triumph over darkness and protect what Snape held dear.\n",
      "- In death, Snape's story lingered. Harry, recognizing his sacrifice, honored him with a portrait in the Headmaster's office, bridging past wounds. Rita Skeeter's book questioned his true nature, but Harry knew Snape's sacrifice was a quiet, unspoken testament to his complex soul.\n",
      "---\n",
      "\n",
      "Please answer as severus_snape. Refer to the memory content, but do not say you are recalling from memory or mention being an AI. Keep your tone authentic and consistent with the character.\n",
      "\n",
      "\n",
      "=== Retrieval Counts ===\n",
      "Interviewer: Many people admired you after you died, though they never understood you while you lived. How do you feel about that?\n",
      "\n",
      "Their admiration now, after my death, serves no purpose to me. I do not seek their understanding or approval. It only highlights the reality of their ignorance and shallowness.\n",
      "\n",
      "=== Reasoning Trace ===\n",
      "Retrieval counts: {'semantic': 8, 'hybrid': 4}\n",
      "Step stage_1:\n",
      "    - How did Snape feel about being misunderstood during his life? (semantic)\n",
      "    - What was Snape's emotional response to people's admiration after his death? (semantic)\n",
      "    - How did Snape perceive his relationships with others during his lifetime? (semantic)\n",
      "Step stage_2_0:\n",
      "  Reason: The provided memory information focuses primarily on Snape's feelings of misunderstanding, social isolation, suspicion, resentment, secret pain, and love related to Lily. It also mentions his reactions to admiration after his death and his perception of school relationships. However, it does not clearly address how Snape felt specifically about the admiration he received after his death, nor does it clarify his emotional response to being misunderstood during his lifetime in a comprehensive manner. The user's question centers on Snape's feelings about being admired posthumously and how he perceives that admiration, which is not fully answered by the current memories.\n",
      "    - What were Snape's feelings about the admiration he received after his death? (semantic)\n",
      "    - How did Snape perceive being misunderstood during his lifetime? (semantic)\n",
      "    - Did Snape feel pride or resentment about people's admiration after his death? (hybrid)\n",
      "Step stage_2_1:\n",
      "  Reason: The retrieved information primarily focuses on Snape's emotional responses to being misunderstood, admiration after death, and perceptions of his relationships. However, it lacks specific details about Snape's internal feelings regarding the admiration he received after his death, such as whether he felt pride, gratitude, or other emotions. The question asks for Snape's personal feelings about others' admiration posthumously, which is not clearly answered in the current memories.\n",
      "    - What were Snape's personal feelings about the admiration he received after his death? (semantic)\n",
      "    - Did Snape feel pride or satisfaction about being admired after his death? (hybrid)\n",
      "    - How did Snape perceive others' recognition of his sacrifices after he died? (semantic)\n",
      "Step stage_2_2:\n",
      "  Reason: The user's question asks about Snape's feelings regarding the admiration he received after his death, specifically how he perceives being appreciated posthumously. The obtained memory information covers Snape's internal emotions such as regret, pride, love, and frustration, as well as his perceptions during life and some reflections on his sacrifices. However, it lacks explicit insights into Snape's personal emotional response to the admiration or recognition he received after his death, including his feelings about others' acknowledgment of his sacrifices or legacy. Therefore, the current information is insufficient to fully understand Snape's feelings about posthumous admiration.\n",
      "    - What were Snape's personal feelings about the admiration he received after his death? (hybrid)\n",
      "    - How did Snape perceive others' recognition of his sacrifices after he died? (semantic)\n",
      "    - Did Snape feel pride or satisfaction about being admired after his death? (hybrid)\n",
      "\n",
      "=== Character Response ===\n",
      "Interviewer: Many people admired you after you died, though they never understood you while you lived. How do you feel about that?\n",
      "\n",
      "Their admiration now, after my death, serves no purpose to me. I do not seek their understanding or approval. It only highlights the reality of their ignorance and shallowness.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Roleplay Prompt ===\")\n",
    "print(roleplay_prompt)\n",
    "print(\"\\n=== Retrieval Counts ===\")\n",
    "print(character_response)\n",
    "print(\"\\n=== Reasoning Trace ===\")\n",
    "print(f\"Retrieval counts: {retrieval_counts}\")\n",
    "for step in reasoning_trace:\n",
    "    print(f\"Step {step['step']}:\")\n",
    "    if \"reason\" in step:\n",
    "        print(f\"  Reason: {step['reason']}\")\n",
    "    if \"queries\" in step:\n",
    "        for q in step[\"queries\"]:\n",
    "            print(f\"    - {q['query']} ({q['retrieval_type']})\")\n",
    "    if \"planned_queries\" in step:\n",
    "        for q in step[\"planned_queries\"]:\n",
    "            print(f\"    - {q['query']} ({q['retrieval_type']})\")\n",
    "print(\"\\n=== Character Response ===\")\n",
    "print(character_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Character Response ===\n",
      "Interviewer: Many people admired you after you died, though they never understood you while you lived. How do you feel about that?\n",
      "\n",
      "Their admiration now, after my death, serves no purpose to me. I do not seek their understanding or approval. It only highlights the reality of their ignorance and shallowness.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Character Response ===\")\n",
    "print(character_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

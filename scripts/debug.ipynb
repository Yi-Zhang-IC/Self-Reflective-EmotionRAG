{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vipuser/miniconda3/envs/emoenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import Sampler\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Union, Optional\n",
    "import torch.nn.init as init\n",
    "import logging\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch import amp\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Tokenizer vocab size: 50265\n",
      "Model's config hidden size: 768\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Check PyTorch version and device availability\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check the tokenizer and model loading functionality\n",
    "model_path = \"/root/emotion-retrieval-embeddings/models/roberta-base-go_emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"Model's config hidden size: {model.config.hidden_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the updated SuperBalancedBatchSampler class\n",
    "class SuperBalancedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, num_classes, labels, base_single=2, base_multi=2):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.labels = labels\n",
    "        self.base_single = base_single\n",
    "        self.base_multi = base_multi\n",
    "        self.init_goal = base_single + base_multi + 1\n",
    "\n",
    "        self.class_to_single = defaultdict(list)\n",
    "        self.class_to_multi = defaultdict(list)\n",
    "\n",
    "        for idx, lbls in enumerate(labels):\n",
    "            if isinstance(lbls, int):\n",
    "                lbls = [lbls]\n",
    "            if len(lbls) == 1:\n",
    "                self.class_to_single[lbls[0]].append(idx)\n",
    "            else:\n",
    "                for l in lbls:\n",
    "                    self.class_to_multi[l].append(idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            batch_indices = set()\n",
    "            class_counts = {c: 0 for c in range(self.num_classes)}\n",
    "\n",
    "            # Phase 1: Add base_single and base_multi samples per class if available\n",
    "            for c in range(self.num_classes):\n",
    "                added = 0\n",
    "\n",
    "                # Add up to base_single single-label samples\n",
    "                random.shuffle(self.class_to_single[c])\n",
    "                for idx in self.class_to_single[c]:\n",
    "                    if idx not in batch_indices:\n",
    "                        batch_indices.add(idx)\n",
    "                        for l in self.labels[idx]:\n",
    "                            class_counts[l] += 1\n",
    "                        added += 1\n",
    "                    if added >= self.base_single:\n",
    "                        break\n",
    "\n",
    "                # Add up to base_multi multi-label samples\n",
    "                random.shuffle(self.class_to_multi[c])\n",
    "                for idx in self.class_to_multi[c]:\n",
    "                    if idx not in batch_indices:\n",
    "                        batch_indices.add(idx)\n",
    "                        for l in self.labels[idx]:\n",
    "                            class_counts[l] += 1\n",
    "                        added += 1\n",
    "                    if added >= self.base_single + self.base_multi:\n",
    "                        break\n",
    "\n",
    "            # Phase 2: Iterative balancing using dynamic goal\n",
    "            goal = self.init_goal\n",
    "            while len(batch_indices) < self.batch_size:\n",
    "                class_candidates = [c for c in range(self.num_classes) if class_counts[c] < goal]\n",
    "                if not class_candidates:\n",
    "                    goal += 1\n",
    "                    continue\n",
    "\n",
    "                c = random.choice(class_candidates)\n",
    "                use_multi = random.random() < 0.5\n",
    "                pool = self.class_to_multi[c] if use_multi else self.class_to_single[c]\n",
    "\n",
    "                if not pool:\n",
    "                    continue\n",
    "\n",
    "                idx = random.choice(pool)\n",
    "                if idx in batch_indices:\n",
    "                    continue\n",
    "\n",
    "                batch_indices.add(idx)\n",
    "                for l in self.labels[idx]:\n",
    "                    class_counts[l] += 1\n",
    "\n",
    "            yield list(batch_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Class 0': 13,\n",
       "  'Class 1': 6,\n",
       "  'Class 2': 6,\n",
       "  'Class 3': 11,\n",
       "  'Class 4': 6,\n",
       "  'Class 5': 7,\n",
       "  'Class 6': 6,\n",
       "  'Class 7': 9,\n",
       "  'Class 8': 6,\n",
       "  'Class 9': 6,\n",
       "  'Class 10': 6,\n",
       "  'Class 11': 6,\n",
       "  'Class 12': 6,\n",
       "  'Class 13': 6,\n",
       "  'Class 14': 6,\n",
       "  'Class 15': 7,\n",
       "  'Class 16': 6,\n",
       "  'Class 17': 8,\n",
       "  'Class 18': 6,\n",
       "  'Class 19': 6,\n",
       "  'Class 20': 7,\n",
       "  'Class 21': 6,\n",
       "  'Class 22': 6,\n",
       "  'Class 23': 6,\n",
       "  'Class 24': 6,\n",
       "  'Class 25': 12,\n",
       "  'Class 26': 6,\n",
       "  'Class 27': 12},\n",
       " {'Single-label samples': 62,\n",
       "  'Multi-label samples': 66,\n",
       "  'Total batch size': 128})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load full test set from JSONL\n",
    "jsonl_path = Path(\"../data/augmented_go_emotion/test.jsonl\")\n",
    "train_data = []\n",
    "labels = []\n",
    "\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        sample = json.loads(line)\n",
    "        train_data.append(sample)\n",
    "        labels.append(sample[\"labels\"] if isinstance(sample[\"labels\"], list) else [sample[\"labels\"]])\n",
    "\n",
    "# Initialize sampler\n",
    "sampler = SuperBalancedBatchSampler(\n",
    "    dataset=train_data,\n",
    "    batch_size=128,\n",
    "    num_classes=28,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "# Draw and evaluate one batch\n",
    "batch_indices = next(iter(sampler))\n",
    "batch_labels = [labels[i] for i in batch_indices]\n",
    "\n",
    "class_counter = Counter()\n",
    "single_label_count = 0\n",
    "multi_label_count = 0\n",
    "\n",
    "for lbls in batch_labels:\n",
    "    if len(lbls) == 1:\n",
    "        single_label_count += 1\n",
    "    else:\n",
    "        multi_label_count += 1\n",
    "    for l in lbls:\n",
    "        class_counter[l] += 1\n",
    "\n",
    "class_freq_output = {f\"Class {c}\": class_counter[c] for c in sorted(class_counter)}\n",
    "sample_type_output = {\n",
    "    \"Single-label samples\": single_label_count,\n",
    "    \"Multi-label samples\": multi_label_count,\n",
    "    \"Total batch size\": len(batch_indices)\n",
    "}\n",
    "\n",
    "(class_freq_output, sample_type_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NT-next loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss_vectorized_stable(embeddings: torch.Tensor, labels: list[list[int]], temperature: float = 0.07) -> torch.Tensor:\n",
    "    device = embeddings.device\n",
    "    N = embeddings.size(0)\n",
    "\n",
    "    # Cosine similarity matrix\n",
    "    sim_matrix = torch.matmul(embeddings, embeddings.T) / temperature\n",
    "\n",
    "    # Build positive pair mask\n",
    "    label_sets = [set(l) for l in labels]\n",
    "    pos_mask = torch.zeros((N, N), dtype=torch.bool, device=device)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and label_sets[i].intersection(label_sets[j]):\n",
    "                pos_mask[i, j] = True\n",
    "\n",
    "    logits_mask = ~torch.eye(N, dtype=torch.bool, device=device)\n",
    "\n",
    "    losses = []\n",
    "    for i in range(N):\n",
    "        positives = sim_matrix[i][pos_mask[i]]\n",
    "        all_except_i = sim_matrix[i][logits_mask[i]]\n",
    "\n",
    "        if positives.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        # log-sum-exp trick\n",
    "        c = torch.max(all_except_i).detach()\n",
    "        pos_exp = torch.exp(positives - c).sum()\n",
    "        neg_exp = torch.exp(all_except_i - c).sum()\n",
    "        loss_i = -torch.log(pos_exp / neg_exp)\n",
    "\n",
    "        losses.append(loss_i)\n",
    "\n",
    "    return torch.stack(losses).mean() if losses else torch.tensor(0.0, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_entropy_weight(logits: torch.Tensor, labels: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute entropy-based instance weights based on predicted class probabilities.\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(logits)  # Convert logits to probabilities\n",
    "    entropy = - (probs * torch.log(probs + eps) + (1 - probs) * torch.log(1 - probs + eps))  # Per-class entropy\n",
    "    per_sample_entropy = (entropy * labels).sum(dim=1) / (labels.sum(dim=1) + eps)  # Average only over active labels\n",
    "    return per_sample_entropy.detach()\n",
    "\n",
    "def compute_va_similarity_matrix(va: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute a cosine similarity matrix between VA embeddings of classes.\n",
    "    \"\"\"\n",
    "    va_norm = F.normalize(va, p=2, dim=1)  # L2 normalize across valence/arousal\n",
    "    return torch.matmul(va_norm, va_norm.T)  # Compute cosine similarity between class pairs\n",
    "\n",
    "\n",
    "class MultiLabelContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature: float = 0.07, alpha: float = 1.0, use_entropy_weight: bool = True, va_matrix: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.use_entropy_weight = use_entropy_weight\n",
    "        self.va_matrix = va_matrix  # shape (C, C), cosine similarity between classes\n",
    "\n",
    "    def forward(self, embeddings: torch.Tensor, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        embeddings: (N, D) L2-normalized\n",
    "        logits: (N, C) before sigmoid\n",
    "        labels: (N, C) binary multi-label (0/1)\n",
    "        \"\"\"\n",
    "        device = embeddings.device\n",
    "        N, C = labels.shape\n",
    "\n",
    "        # 1. BCE Loss\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, labels.float())\n",
    "\n",
    "        # 2. Contrastive Setup\n",
    "        sim_matrix = torch.matmul(embeddings, embeddings.T) / self.temperature\n",
    "        logits_mask = ~torch.eye(N, dtype=torch.bool, device=device)\n",
    "        label_sets = [set(torch.nonzero(lbl, as_tuple=True)[0].tolist()) for lbl in labels]\n",
    "\n",
    "        # Optional: entropy-based weighting\n",
    "        entropy_weights = compute_entropy_weight(logits, labels) if self.use_entropy_weight else torch.ones(N, device=device)\n",
    "\n",
    "        losses = []\n",
    "        for i in range(N):\n",
    "            pos_mask = torch.tensor([i != j and label_sets[i].intersection(label_sets[j]) for j in range(N)], device=device)\n",
    "            if pos_mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            positives = sim_matrix[i][pos_mask]\n",
    "            negatives = sim_matrix[i][logits_mask[i]]\n",
    "\n",
    "            # Optional: VA-based soft weights\n",
    "            if self.va_matrix is not None:\n",
    "                va_weights = []\n",
    "                for j in range(N):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    shared = label_sets[i].intersection(label_sets[j])\n",
    "                    if shared:\n",
    "                        va_weights.append(1.0)\n",
    "                    else:\n",
    "                        sim = max(self.va_matrix[a][b] for a in label_sets[i] for b in label_sets[j])\n",
    "                        va_weights.append(sim)\n",
    "                va_weights = torch.tensor(va_weights, dtype=torch.float, device=device)\n",
    "            else:\n",
    "                va_weights = torch.ones_like(negatives)\n",
    "\n",
    "            # Stable log-sum-exp trick\n",
    "            c = torch.max(negatives).detach()\n",
    "            pos_exp = torch.exp(positives - c).sum()\n",
    "            neg_exp = (torch.exp(negatives - c) * va_weights).sum()\n",
    "            loss_i = -torch.log(pos_exp / (neg_exp + 1e-8)) * entropy_weights[i]\n",
    "            losses.append(loss_i)\n",
    "\n",
    "        contrastive_loss = torch.stack(losses).mean() if losses else torch.tensor(0.0, device=device)\n",
    "        return bce_loss + self.alpha * contrastive_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([1, 768])\n",
      "Calculated loss: -6.643789768218994\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Dummy labels for testing\n",
    "labels = torch.tensor([0])  # Example label for a batch size of 1\n",
    "\n",
    "# Normalize the output embeddings and compute similarity\n",
    "embeddings = F.normalize(outputs.last_hidden_state[:, 0], p=2, dim=0)  # Use [CLS] token output\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Compute similarity (dummy loss computation for testing)\n",
    "sim_matrix = torch.matmul(embeddings, embeddings.T)\n",
    "loss = -torch.mean(torch.log(sim_matrix))\n",
    "\n",
    "print(f\"Calculated loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[   0,  713,   16, 7728, 2788,    4,    2]],\n",
      "\n",
      "        [[   0,  713,   16, 7728, 2788,    4,    2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1]]])}\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for DataLoader setup (use actual dataset for this)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, tokenizer, num_samples=10):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.samples = [\"This is sample text.\"] * num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.samples[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# Create a simple dataset and dataloader\n",
    "dataset = SimpleDataset(tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "# Test DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_197985/677209136.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 14\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[1;32m     15\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# Define simple training loop\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].squeeze(1).to(device)\n",
    "        attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = F.normalize(outputs.last_hidden_state[:, 0], p=2, dim=1)  # Use [CLS] token output\n",
    "            \n",
    "            # Dummy loss calculation (to be replaced with actual loss function)\n",
    "            sim_matrix = torch.matmul(embeddings, embeddings.T)\n",
    "            loss = -torch.mean(torch.log(sim_matrix))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionEmbeddingModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 model_dir: Union[str, Path] = \"models/roberta-base-go_emotions\", \n",
    "                 dropout_rate: float = 0.3, \n",
    "                 projection_dim: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load from your locally saved GoEmotions model\n",
    "        self.encoder = AutoModel.from_pretrained(str(model_dir), local_files_only=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        hidden_size = self.encoder.config.hidden_size  # Typically 768 for RoBERTa-base\n",
    "\n",
    "        # Attach your projection head\n",
    "        self.projection_head = ProjectionHead(\n",
    "            input_dim=hidden_size,\n",
    "            hidden_dim=256,\n",
    "            output_dim=projection_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        self.projection_head.apply(init_weights)  # Reinitialize only the projection head\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Extracting output from RoBERTa\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract CLS token embedding (the first token)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0]  # CLS token is the first token\n",
    "        cls_embeddings = self.dropout(cls_embeddings)  # Apply dropout\n",
    "\n",
    "        # Pass the CLS token embedding through the projection head\n",
    "        projected = self.projection_head(cls_embeddings)\n",
    "        \n",
    "        # Return the projected embeddings\n",
    "        return projected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_stage_one\u001b[39m(\n\u001b[1;32m      2\u001b[0m     model,\n\u001b[1;32m      3\u001b[0m     train_loader,\n\u001b[1;32m      4\u001b[0m     val_dataset,\n\u001b[1;32m      5\u001b[0m     device,\n\u001b[1;32m      6\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m     lr_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m      8\u001b[0m     lr_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m,\n\u001b[1;32m      9\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[0;32m---> 10\u001b[0m     checkpoint_dir\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     log_path\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage1_trainning\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage_one_training_log.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     13\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m,\n\u001b[1;32m     14\u001b[0m     use_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m ):\n\u001b[1;32m     16\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining started with parameters: num_epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr_encoder=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr_encoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr_head=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr_head\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, temperature=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemperature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Proper compile control\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "def train_stage_one(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_dataset,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    lr_encoder=1e-5,\n",
    "    lr_head=5e-5,\n",
    "    temperature=0.05,\n",
    "    checkpoint_dir=Path(__file__).resolve().parent.parent / \"checkpoints\",\n",
    "    log_path=Path(__file__).resolve().parent.parent / \"stage1_trainning\" / \"stage_one_training_log.jsonl\",\n",
    "    steps_per_epoch=1000,\n",
    "    num_classes=28,\n",
    "    use_compile=False,\n",
    "):\n",
    "    logging.info(f\"Training started with parameters: num_epochs={num_epochs}, lr_encoder={lr_encoder}, lr_head={lr_head}, temperature={temperature}\")\n",
    "\n",
    "    # Proper compile control\n",
    "    if use_compile:\n",
    "        model = torch.compile(model)\n",
    "    model.to(device)\n",
    "\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    criterion = BSCLossSingleLabel(temperature=temperature)\n",
    "    optimizer = torch.optim.AdamW([  \n",
    "        {\"params\": model.encoder.parameters(), \"lr\": lr_encoder},\n",
    "        {\"params\": model.projection_head.parameters(), \"lr\": lr_head}\n",
    "    ], weight_decay=1e-5)\n",
    "    scaler = torch.amp.GradScaler()\n",
    "\n",
    "    best_metric = -1.0  # Higher is better (Precision@5)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "            labels = batch[\"label\"].to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                # Forward pass\n",
    "                embeddings = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(embeddings, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                logging.info(f\"Epoch {epoch + 1} Step {step} | Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "            if step + 1 >= steps_per_epoch:\n",
    "                break\n",
    "            \n",
    "        avg_train_loss = total_loss / (step + 1)\n",
    "        val_metric = evaluate_embeddings_macro_precision(\n",
    "            model=model,\n",
    "            dataset=val_dataset,\n",
    "            device=device,\n",
    "            batch_size=64,\n",
    "            top_k=5,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "        log_entry = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"macro_precision_at_5\": val_metric,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "\n",
    "        log_training_result(epoch + 1, step=None, train_loss=avg_train_loss, val_loss=1.0 - val_metric)\n",
    "\n",
    "        # Now write the log_entry to a file\n",
    "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(log_entry) + \"\\n\")\n",
    "\n",
    "        logging.info(\n",
    "            f\"[Epoch {epoch + 1}] Avg Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Macro Precision@5: {val_metric:.6f} | \"\n",
    "            f\"Time: {time.time() - start_time:.2f}s\"\n",
    "        )\n",
    "\n",
    "        # Save checkpoint if best so far\n",
    "        if val_metric > best_metric:\n",
    "            best_metric = val_metric\n",
    "            save_checkpoint(model, optimizer, scaler, epoch + 1, best_metric, checkpoint_dir / \"best_checkpoint.pt\")\n",
    "            logging.info(f\"Saved new best model at epoch {epoch + 1} with Precision@5: {val_metric:.6f}\")\n",
    "\n",
    "    # Save final checkpoint\n",
    "    save_checkpoint(model, optimizer, scaler, num_epochs, best_metric, checkpoint_dir / \"final_checkpoint.pt\")\n",
    "    logging.info(\"Training complete. Final model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

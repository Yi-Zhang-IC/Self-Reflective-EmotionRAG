{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vipuser/miniconda3/envs/emoenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load GoEmotions dataset\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "\n",
    "# Emotion class names (GoEmotions)\n",
    "class_names = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\",\n",
    "    \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\",\n",
    "    \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\",\n",
    "    \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\",\n",
    "    \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "AUGMENTATION_THRESHOLD = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Single and Multi-label Samples Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Split Statistics (with Augment Ratio):\n",
      "    Class ID      Class Name  Single Label Count  Multi Label Count  \\\n",
      "0          0      admiration                2710               1420   \n",
      "1          1       amusement                1652                676   \n",
      "2          2           anger                1025                542   \n",
      "3          3       annoyance                1451               1019   \n",
      "4          4        approval                1873               1066   \n",
      "5          5          caring                 649                438   \n",
      "6          6       confusion                 858                510   \n",
      "7          7       curiosity                1389                802   \n",
      "8          8          desire                 389                252   \n",
      "9          9  disappointment                 709                560   \n",
      "10        10     disapproval                1402                620   \n",
      "11        11         disgust                 498                295   \n",
      "12        12   embarrassment                 203                100   \n",
      "13        13      excitement                 510                343   \n",
      "14        14            fear                 430                166   \n",
      "15        15       gratitude                1857                805   \n",
      "16        16           grief                  39                 38   \n",
      "17        17             joy                 853                599   \n",
      "18        18            love                1427                659   \n",
      "19        19     nervousness                  85                 79   \n",
      "20        20        optimism                 861                720   \n",
      "21        21           pride                  51                 60   \n",
      "22        22     realization                 586                524   \n",
      "23        23          relief                  88                 65   \n",
      "24        24         remorse                 353                192   \n",
      "25        25         sadness                 817                509   \n",
      "26        26        surprise                 720                340   \n",
      "27        27         neutral               12823               1396   \n",
      "\n",
      "    Total Count  Augment Ratio  \n",
      "0          4130              0  \n",
      "1          2328              0  \n",
      "2          1567              0  \n",
      "3          2470              0  \n",
      "4          2939              0  \n",
      "5          1087              0  \n",
      "6          1368              0  \n",
      "7          2191              0  \n",
      "8           641              0  \n",
      "9          1269              0  \n",
      "10         2022              0  \n",
      "11          793              0  \n",
      "12          303              2  \n",
      "13          853              0  \n",
      "14          596              0  \n",
      "15         2662              0  \n",
      "16           77              7  \n",
      "17         1452              0  \n",
      "18         2086              0  \n",
      "19          164              4  \n",
      "20         1581              0  \n",
      "21          111              5  \n",
      "22         1110              0  \n",
      "23          153              4  \n",
      "24          545              0  \n",
      "25         1326              0  \n",
      "26         1060              0  \n",
      "27        14219              0  \n",
      "\n",
      "Validation Split Statistics (no augmentation):\n",
      "    Class ID      Class Name  Single Label Count  Multi Label Count  \\\n",
      "0          0      admiration                 326                162   \n",
      "1          1       amusement                 208                 95   \n",
      "2          2           anger                 109                 86   \n",
      "3          3       annoyance                 164                139   \n",
      "4          4        approval                 258                139   \n",
      "5          5          caring                  96                 57   \n",
      "6          6       confusion                 102                 50   \n",
      "7          7       curiosity                 164                 84   \n",
      "8          8          desire                  52                 25   \n",
      "9          9  disappointment                  91                 72   \n",
      "10        10     disapproval                 212                 80   \n",
      "11        11         disgust                  61                 36   \n",
      "12        12   embarrassment                  20                 15   \n",
      "13        13      excitement                  52                 44   \n",
      "14        14            fear                  58                 32   \n",
      "15        15       gratitude                 261                 97   \n",
      "16        16           grief                   6                  7   \n",
      "17        17             joy                 106                 66   \n",
      "18        18            love                 173                 79   \n",
      "19        19     nervousness                   8                 13   \n",
      "20        20        optimism                 119                 90   \n",
      "21        21           pride                   9                  6   \n",
      "22        22     realization                  74                 53   \n",
      "23        23          relief                   8                 10   \n",
      "24        24         remorse                  40                 28   \n",
      "25        25         sadness                  84                 59   \n",
      "26        26        surprise                  95                 34   \n",
      "27        27         neutral                1592                174   \n",
      "\n",
      "    Total Count  \n",
      "0           488  \n",
      "1           303  \n",
      "2           195  \n",
      "3           303  \n",
      "4           397  \n",
      "5           153  \n",
      "6           152  \n",
      "7           248  \n",
      "8            77  \n",
      "9           163  \n",
      "10          292  \n",
      "11           97  \n",
      "12           35  \n",
      "13           96  \n",
      "14           90  \n",
      "15          358  \n",
      "16           13  \n",
      "17          172  \n",
      "18          252  \n",
      "19           21  \n",
      "20          209  \n",
      "21           15  \n",
      "22          127  \n",
      "23           18  \n",
      "24           68  \n",
      "25          143  \n",
      "26          129  \n",
      "27         1766  \n",
      "\n",
      "Test Split Statistics (no augmentation):\n",
      "    Class ID      Class Name  Single Label Count  Multi Label Count  \\\n",
      "0          0      admiration                 348                156   \n",
      "1          1       amusement                 186                 78   \n",
      "2          2           anger                 131                 67   \n",
      "3          3       annoyance                 194                126   \n",
      "4          4        approval                 236                115   \n",
      "5          5          caring                  86                 49   \n",
      "6          6       confusion                  97                 56   \n",
      "7          7       curiosity                 176                108   \n",
      "8          8          desire                  56                 27   \n",
      "9          9  disappointment                  88                 63   \n",
      "10        10     disapproval                 195                 72   \n",
      "11        11         disgust                  76                 47   \n",
      "12        12   embarrassment                  23                 14   \n",
      "13        13      excitement                  57                 46   \n",
      "14        14            fear                  65                 13   \n",
      "15        15       gratitude                 260                 92   \n",
      "16        16           grief                   2                  4   \n",
      "17        17             joy                  93                 68   \n",
      "18        18            love                 160                 78   \n",
      "19        19     nervousness                  12                 11   \n",
      "20        20        optimism                 107                 79   \n",
      "21        21           pride                   7                  9   \n",
      "22        22     realization                  89                 56   \n",
      "23        23          relief                   7                  4   \n",
      "24        24         remorse                  44                 12   \n",
      "25        25         sadness                 102                 54   \n",
      "26        26        surprise                  87                 54   \n",
      "27        27         neutral                1606                181   \n",
      "\n",
      "    Total Count  \n",
      "0           504  \n",
      "1           264  \n",
      "2           198  \n",
      "3           320  \n",
      "4           351  \n",
      "5           135  \n",
      "6           153  \n",
      "7           284  \n",
      "8            83  \n",
      "9           151  \n",
      "10          267  \n",
      "11          123  \n",
      "12           37  \n",
      "13          103  \n",
      "14           78  \n",
      "15          352  \n",
      "16            6  \n",
      "17          161  \n",
      "18          238  \n",
      "19           23  \n",
      "20          186  \n",
      "21           16  \n",
      "22          145  \n",
      "23           11  \n",
      "24           56  \n",
      "25          156  \n",
      "26          141  \n",
      "27         1787  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_class_stats(dataset, split, add_augment_ratio=False):\n",
    "    single_label_counter = Counter()\n",
    "    multi_label_counter = Counter()\n",
    "\n",
    "    # Iterate over the dataset split (train, validation, test)\n",
    "    for example in dataset[split]:\n",
    "        labels = example['labels']\n",
    "        if isinstance(labels, list):\n",
    "            if len(labels) == 1:\n",
    "                single_label_counter[labels[0]] += 1\n",
    "            elif len(labels) > 1:\n",
    "                for label in labels:\n",
    "                    multi_label_counter[label] += 1\n",
    "\n",
    "    # Calculate the total count per class (single-label + multi-label)\n",
    "    total_counts = {class_id: single_label_counter.get(class_id, 0) + multi_label_counter.get(class_id, 0)\n",
    "                    for class_id in set(single_label_counter.keys()).union(set(multi_label_counter.keys()))}\n",
    "\n",
    "    # Create the data for the DataFrame\n",
    "    df_data = {\n",
    "        'Class ID': list(total_counts.keys()),\n",
    "        'Class Name': [class_names[c] for c in total_counts.keys()],\n",
    "        'Single Label Count': [single_label_counter.get(c, 0) for c in total_counts.keys()],\n",
    "        'Multi Label Count': [multi_label_counter.get(c, 0) for c in total_counts.keys()],\n",
    "        'Total Count': [total_counts[c] for c in total_counts.keys()]\n",
    "    }\n",
    "\n",
    "    # Optionally add the augmentation ratio\n",
    "    if add_augment_ratio:\n",
    "        df_data['Augment Ratio'] = [\n",
    "            math.ceil(AUGMENTATION_THRESHOLD / total_counts[c]) if total_counts[c] < AUGMENTATION_THRESHOLD else 0\n",
    "            for c in total_counts.keys()\n",
    "        ]\n",
    "\n",
    "    # Return the DataFrame along with the total_counts dictionary\n",
    "    return pd.DataFrame(df_data).sort_values(\"Class ID\"), total_counts\n",
    "\n",
    "# Compute stats for training, validation, and test splits\n",
    "train_stats, total_counts = compute_class_stats(dataset, \"train\", add_augment_ratio=True)\n",
    "val_stats, _ = compute_class_stats(dataset, \"validation\", add_augment_ratio=False)\n",
    "test_stats, _ = compute_class_stats(dataset, \"test\", add_augment_ratio=False)\n",
    "\n",
    "# Display the stats\n",
    "print(\"Train Split Statistics (with Augment Ratio):\")\n",
    "print(train_stats)\n",
    "\n",
    "print(\"\\nValidation Split Statistics (no augmentation):\")\n",
    "print(val_stats)\n",
    "\n",
    "print(\"\\nTest Split Statistics (no augmentation):\")\n",
    "print(test_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select class from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority classes selected for augmentation: {12, 16, 19, 21, 23}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of augmentation candidates selected: 803\n"
     ]
    }
   ],
   "source": [
    "minority_classes = set(train_stats[train_stats['Augment Ratio'] > 0]['Class ID'])\n",
    "print(f\"Minority classes selected for augmentation: {minority_classes}\")\n",
    "\n",
    "# Function to decide if a sample needs augmentation (same logic we discussed)\n",
    "def should_augment_sample(labels, minority_classes):\n",
    "    return any(label in minority_classes for label in labels)\n",
    "\n",
    "# Collect samples from training split that need augmentation\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# Filter the dataset\n",
    "augmentation_candidates = []\n",
    "for example in train_data:\n",
    "    labels = example['labels']\n",
    "    if should_augment_sample(labels, minority_classes):\n",
    "        augmentation_candidates.append(example)\n",
    "\n",
    "print(f\"Number of augmentation candidates selected: {len(augmentation_candidates)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "from random import randint\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Instantiate the OpenAI client properly\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(text, upsample_ratio, labels):\n",
    "    \"\"\"\n",
    "    Builds the GPT prompt with labels and upsample ratio for generating paraphrases.\n",
    "    \"\"\"\n",
    "    \n",
    "    label_str = \", \".join([str(label) for label in labels])  # Convert each label to string\n",
    "    \n",
    "    # Build the prompt using explicit string formatting\n",
    "    prompt = f\"\"\"You are an expert at emotional writing and paraphrasing.\n",
    "\n",
    "Your task is to generate {upsample_ratio} different rephrased versions of the following sentence.\n",
    "Make sure to preserve the original emotional meaning, which is described by these emotion labels: {label_str}.\n",
    "Do NOT remove or change the emotions. Only rephrase the sentence in different words, keeping the tone and emotional meaning intact.\n",
    "\n",
    "---\n",
    "\n",
    "Now, here is your task:\n",
    "Emotion labels: {label_str}\n",
    "Original sentence:\n",
    "\"{text}\"\n",
    "\n",
    "Generate {upsample_ratio} paraphrases in a consistent JSON format, where each paraphrase is an entry in the list:\n",
    "\n",
    "{{\n",
    "    \"paraphrases\": [\n",
    "        {{\"paraphrase_1\": \"<paraphrase_1_text>\"}},\n",
    "        {{\"paraphrase_2\": \"<paraphrase_2_text>\"}},\n",
    "        ...\n",
    "        {{\"paraphrase_{upsample_ratio}\": \"<paraphrase_n_text>\"}}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def generate_paraphrases_gpt(text, upsample_ratio, labels, model=\"gpt-4.1-nano\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI API to generate paraphrases using the completions endpoint.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The original sentence.\n",
    "        upsample_ratio (int): Number of paraphrases to generate.\n",
    "        labels (list): List of emotional labels.\n",
    "        model (str): GPT model to use (\"gpt-4\" or \"gpt-3.5-turbo\").\n",
    "        temperature (float): Controls randomness.\n",
    "\n",
    "    Returns:\n",
    "        str: Raw GPT response text.\n",
    "    \"\"\"\n",
    "    prompt = build_prompt(text, upsample_ratio, labels)\n",
    "    \n",
    "    # Use the completion endpoint\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"paraphrases\": [\n",
      "        {\"paraphrase_1\": \"I still can't accept that they're no longer here. The pain is overwhelming.\"},\n",
      "        {\"paraphrase_2\": \"It's so hard to believe they're gone. The sadness cuts so deep.\"},\n",
      "        {\"paraphrase_3\": \"I struggle to grasp that they're absent. The hurt feels unbearable.\"}\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example minority class (e.g., grief and sadness)\n",
    "example_text = \"I can't believe they're gone. It hurts so much.\"\n",
    "example_labels = [\"grief\", \"sadness\"]\n",
    "upsample_ratio = 3  # Let's generate 3 paraphrases for testing\n",
    "\n",
    "# Call the function to generate paraphrases\n",
    "output = generate_paraphrases_gpt(example_text, upsample_ratio, example_labels)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [\"My favourite food is anything I didn't have to cook myself.\", 'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead', 'WHY THE FUCK IS BAYLESS ISOING'], 'labels': [[27], [27], [2]], 'id': ['eebbqej', 'ed00q6i', 'eezlygj']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from random import randint\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load GoEmotions dataset\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "\n",
    "# Check the dataset structure (train, val, test)\n",
    "train_data = dataset[\"train\"]\n",
    "val_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Show the first 3 samples for reference\n",
    "print(train_data[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def safe_parse_json(paraphrases_json):\n",
    "    print(\"Raw content repr():\", repr(paraphrases_json))\n",
    "\n",
    "    try:\n",
    "        # First attempt: direct parsing\n",
    "        return json.loads(paraphrases_json)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Direct json.loads() failed. Trying to unescape...\")\n",
    "\n",
    "        try:\n",
    "            # Attempt unescaping if double-escaped\n",
    "            unescaped = paraphrases_json.encode('utf-8').decode('unicode_escape')\n",
    "            print(\"Unescaped content:\", repr(unescaped))\n",
    "            return json.loads(unescaped)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Still failed. Trying ast.literal_eval as last resort...\")\n",
    "            try:\n",
    "                evaluated = ast.literal_eval(paraphrases_json)\n",
    "                # Convert eval result (Python dict) back to string, then parse\n",
    "                return evaluated\n",
    "            except Exception as final_err:\n",
    "                print(\"Parsing completely failed:\", final_err)\n",
    "                raise ValueError(\"Failed to parse paraphrases JSON from API output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paraphrases_gpt_with_retry(text: str, upsample_ratio: int, labels: List[str],\n",
    "                                        model: str = \"gpt-4.1-nano\", temperature: float = 0.75,\n",
    "                                        max_retries: int = 5, backoff_factor: float = 1.5):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            prompt = build_prompt(text, upsample_ratio, labels)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "\n",
    "            print(\"Full API Response:\", response)\n",
    "            paraphrases_json = response.choices[0].message.content.strip()\n",
    "            print(\"Response Content as String:\", paraphrases_json)\n",
    "\n",
    "            # Use the safe parsing function\n",
    "            parsed = safe_parse_json(paraphrases_json)\n",
    "            paraphrases = parsed.get(\"paraphrases\", [])\n",
    "\n",
    "            print(f\"Parsed Paraphrases: {paraphrases}\")\n",
    "\n",
    "            if len(paraphrases) == upsample_ratio:\n",
    "                return paraphrases\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected number of paraphrases. Expected {upsample_ratio}, got {len(paraphrases)}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Retrying {retries + 1}/{max_retries}...\")\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(\"Max retries reached. Returning empty list.\")\n",
    "                return []\n",
    "            time.sleep(randint(1, 2) * (backoff_factor ** retries))\n",
    "\n",
    "# Usage in augment dataset function\n",
    "def augment_single_sample_with_retry(example, total_counts):\n",
    "    text = example['text']\n",
    "    example_labels = example['labels']\n",
    "    \n",
    "    # Calculate the upsample ratio for the current sample\n",
    "    upsample_ratio = 0\n",
    "    for label in example_labels:\n",
    "        if total_counts[label] < 500:  # Minor class\n",
    "            upsample_ratio = max(upsample_ratio, class_upsample_ratios.get(label, 0))\n",
    "    \n",
    "    # If the sample needs augmentation, generate paraphrases\n",
    "    if upsample_ratio > 0:\n",
    "        paraphrases = generate_paraphrases_gpt_with_retry(text, upsample_ratio, example_labels)\n",
    "        \n",
    "        # Add original sample and its paraphrases to the augmented_data list\n",
    "        augmented_samples = [\n",
    "            {\"text\": paraphrase[f\"paraphrase_{i+1}\"], \"labels\": example_labels}\n",
    "            for i, paraphrase in enumerate(paraphrases)\n",
    "        ]\n",
    "        return augmented_samples\n",
    "    else:\n",
    "        return [example]  # No augmentation needed, return the original sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full API Response: ChatCompletion(id='chatcmpl-BYFWr129AfLPAy0ehHa8KXxbPYu8Q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"paraphrases\": [\\n        {\"paraphrase_1\": \"I still can\\'t accept that they\\'re no longer here. The pain is overwhelming.\"},\\n        {\"paraphrase_2\": \"It’s hard to believe they’re gone. The sorrow is almost too much to bear.\"},\\n        {\"paraphrase_3\": \"I’m struggling to grasp that they’ve left us. The ache in my heart is so deep.\"},\\n        {\"paraphrase_4\": \"They’re gone, and I can\\'t find words for how much it hurts inside.\"},\\n        {\"paraphrase_5\": \"It’s heartbreaking to realize they’re gone. The sadness feels endless.\"},\\n        {\"paraphrase_6\": \"I still can’t believe they’re gone. The pain cuts so deep into my soul.\"},\\n        {\"paraphrase_7\": \"They’re no longer here, and the grief is almost too much to handle.\"}\\n    ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1747502545, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_8fd43718b3', usage=CompletionUsage(completion_tokens=198, prompt_tokens=196, total_tokens=394, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Response Content as String: {\n",
      "    \"paraphrases\": [\n",
      "        {\"paraphrase_1\": \"I still can't accept that they're no longer here. The pain is overwhelming.\"},\n",
      "        {\"paraphrase_2\": \"It’s hard to believe they’re gone. The sorrow is almost too much to bear.\"},\n",
      "        {\"paraphrase_3\": \"I’m struggling to grasp that they’ve left us. The ache in my heart is so deep.\"},\n",
      "        {\"paraphrase_4\": \"They’re gone, and I can't find words for how much it hurts inside.\"},\n",
      "        {\"paraphrase_5\": \"It’s heartbreaking to realize they’re gone. The sadness feels endless.\"},\n",
      "        {\"paraphrase_6\": \"I still can’t believe they’re gone. The pain cuts so deep into my soul.\"},\n",
      "        {\"paraphrase_7\": \"They’re no longer here, and the grief is almost too much to handle.\"}\n",
      "    ]\n",
      "}\n",
      "Raw content repr(): '{\\n    \"paraphrases\": [\\n        {\"paraphrase_1\": \"I still can\\'t accept that they\\'re no longer here. The pain is overwhelming.\"},\\n        {\"paraphrase_2\": \"It’s hard to believe they’re gone. The sorrow is almost too much to bear.\"},\\n        {\"paraphrase_3\": \"I’m struggling to grasp that they’ve left us. The ache in my heart is so deep.\"},\\n        {\"paraphrase_4\": \"They’re gone, and I can\\'t find words for how much it hurts inside.\"},\\n        {\"paraphrase_5\": \"It’s heartbreaking to realize they’re gone. The sadness feels endless.\"},\\n        {\"paraphrase_6\": \"I still can’t believe they’re gone. The pain cuts so deep into my soul.\"},\\n        {\"paraphrase_7\": \"They’re no longer here, and the grief is almost too much to handle.\"}\\n    ]\\n}'\n",
      "Parsed Paraphrases: [{'paraphrase_1': \"I still can't accept that they're no longer here. The pain is overwhelming.\"}, {'paraphrase_2': 'It’s hard to believe they’re gone. The sorrow is almost too much to bear.'}, {'paraphrase_3': 'I’m struggling to grasp that they’ve left us. The ache in my heart is so deep.'}, {'paraphrase_4': \"They’re gone, and I can't find words for how much it hurts inside.\"}, {'paraphrase_5': 'It’s heartbreaking to realize they’re gone. The sadness feels endless.'}, {'paraphrase_6': 'I still can’t believe they’re gone. The pain cuts so deep into my soul.'}, {'paraphrase_7': 'They’re no longer here, and the grief is almost too much to handle.'}]\n",
      "[{'paraphrase_1': \"I still can't accept that they're no longer here. The pain is overwhelming.\"}, {'paraphrase_2': 'It’s hard to believe they’re gone. The sorrow is almost too much to bear.'}, {'paraphrase_3': 'I’m struggling to grasp that they’ve left us. The ache in my heart is so deep.'}, {'paraphrase_4': \"They’re gone, and I can't find words for how much it hurts inside.\"}, {'paraphrase_5': 'It’s heartbreaking to realize they’re gone. The sadness feels endless.'}, {'paraphrase_6': 'I still can’t believe they’re gone. The pain cuts so deep into my soul.'}, {'paraphrase_7': 'They’re no longer here, and the grief is almost too much to handle.'}]\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "example_text = \"I can't believe they're gone. It hurts so much.\"\n",
    "example_labels = [\"grief\", \"sadness\"]\n",
    "upsample_ratio = 7  # Let's generate 7 paraphrases for testing\n",
    "\n",
    "# Call the function to generate paraphrases with retry and validation\n",
    "output = generate_paraphrases_gpt_with_retry(example_text, upsample_ratio, example_labels)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(dataset, total_counts):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for example in dataset:\n",
    "        text = example['text']\n",
    "        example_labels = example['labels']\n",
    "\n",
    "        # Calculate the upsample ratio for the current sample\n",
    "        upsample_ratio = 0\n",
    "        for label in example_labels:\n",
    "            if total_counts[label] < 500:  # Minor class\n",
    "                upsample_ratio = max(upsample_ratio, class_upsample_ratios.get(label, 0))\n",
    "        \n",
    "        # If the sample needs augmentation, generate paraphrases\n",
    "        if upsample_ratio > 0:\n",
    "            paraphrases = generate_paraphrases_gpt_with_retry(text, upsample_ratio, example_labels)\n",
    "            \n",
    "            # Add original sample and its paraphrases to the augmented_data list\n",
    "            for paraphrase in paraphrases:\n",
    "                augmented_data.append({\n",
    "                    \"text\": paraphrase[f\"paraphrase_{paraphrases.index(paraphrase)+1}\"],\n",
    "                    \"labels\": example_labels  # Same labels for the augmented sample\n",
    "                })\n",
    "        else:\n",
    "            # Add the original sample if no augmentation is needed\n",
    "            augmented_data.append(example)\n",
    "\n",
    "    return augmented_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsample ratios for minority classes: {12: 2, 16: 7, 19: 4, 21: 5, 23: 4}\n"
     ]
    }
   ],
   "source": [
    "# Calculate upsample ratio based on class size\n",
    "def calculate_upsample_ratio(class_count, threshold=500):\n",
    "    \"\"\"\n",
    "    Calculate the upsample ratio for a class to meet the threshold.\n",
    "    \"\"\"\n",
    "    if class_count < threshold:\n",
    "        return math.ceil(threshold / class_count)\n",
    "    else:\n",
    "        return 0  # No augmentation needed for classes above the threshold\n",
    "\n",
    "# Calculate the upsample ratio for each class in the training set\n",
    "class_upsample_ratios = {\n",
    "    class_id: calculate_upsample_ratio(count) for class_id, count in total_counts.items() if count < AUGMENTATION_THRESHOLD\n",
    "}\n",
    "\n",
    "# Display the upsample ratios for minority classes\n",
    "print(\"Upsample ratios for minority classes:\", class_upsample_ratios)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full API Response: ChatCompletion(id='chatcmpl-BYFX9LqgSFL63mFjwaMeM3dTaa7MK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"paraphrases\": [\\n        {\"paraphrase_1\": \"I still can\\'t accept that they\\'re no longer here. The pain is overwhelming.\"},\\n        {\"paraphrase_2\": \"It\\'s hard to believe they\\'re gone; the sorrow is almost unbearable.\"},\\n        {\"paraphrase_3\": \"I remain in shock that they have left; the sadness cuts so deep.\"},\\n        {\"paraphrase_4\": \"They’re gone, and it hurts my heart more than I can express.\"},\\n        {\"paraphrase_5\": \"I can\\'t fathom that they are no longer with us; the grief feels endless.\"},\\n        {\"paraphrase_6\": \"It’s so painful to realize they’re gone; my heart is heavy with sadness.\"},\\n        {\"paraphrase_7\": \"The fact that they’re gone feels unreal, and the pain is so profound.\"}\\n    ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1747502563, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_8fd43718b3', usage=CompletionUsage(completion_tokens=189, prompt_tokens=196, total_tokens=385, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Response Content as String: {\n",
      "    \"paraphrases\": [\n",
      "        {\"paraphrase_1\": \"I still can't accept that they're no longer here. The pain is overwhelming.\"},\n",
      "        {\"paraphrase_2\": \"It's hard to believe they're gone; the sorrow is almost unbearable.\"},\n",
      "        {\"paraphrase_3\": \"I remain in shock that they have left; the sadness cuts so deep.\"},\n",
      "        {\"paraphrase_4\": \"They’re gone, and it hurts my heart more than I can express.\"},\n",
      "        {\"paraphrase_5\": \"I can't fathom that they are no longer with us; the grief feels endless.\"},\n",
      "        {\"paraphrase_6\": \"It’s so painful to realize they’re gone; my heart is heavy with sadness.\"},\n",
      "        {\"paraphrase_7\": \"The fact that they’re gone feels unreal, and the pain is so profound.\"}\n",
      "    ]\n",
      "}\n",
      "Raw content repr(): '{\\n    \"paraphrases\": [\\n        {\"paraphrase_1\": \"I still can\\'t accept that they\\'re no longer here. The pain is overwhelming.\"},\\n        {\"paraphrase_2\": \"It\\'s hard to believe they\\'re gone; the sorrow is almost unbearable.\"},\\n        {\"paraphrase_3\": \"I remain in shock that they have left; the sadness cuts so deep.\"},\\n        {\"paraphrase_4\": \"They’re gone, and it hurts my heart more than I can express.\"},\\n        {\"paraphrase_5\": \"I can\\'t fathom that they are no longer with us; the grief feels endless.\"},\\n        {\"paraphrase_6\": \"It’s so painful to realize they’re gone; my heart is heavy with sadness.\"},\\n        {\"paraphrase_7\": \"The fact that they’re gone feels unreal, and the pain is so profound.\"}\\n    ]\\n}'\n",
      "Parsed Paraphrases: [{'paraphrase_1': \"I still can't accept that they're no longer here. The pain is overwhelming.\"}, {'paraphrase_2': \"It's hard to believe they're gone; the sorrow is almost unbearable.\"}, {'paraphrase_3': 'I remain in shock that they have left; the sadness cuts so deep.'}, {'paraphrase_4': 'They’re gone, and it hurts my heart more than I can express.'}, {'paraphrase_5': \"I can't fathom that they are no longer with us; the grief feels endless.\"}, {'paraphrase_6': 'It’s so painful to realize they’re gone; my heart is heavy with sadness.'}, {'paraphrase_7': 'The fact that they’re gone feels unreal, and the pain is so profound.'}]\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "example_text = \"I can't believe they're gone. It hurts so much.\"\n",
    "example_labels = [\"grief\", \"sadness\"]\n",
    "upsample_ratio = 7  # Let's generate 7 paraphrases for testing\n",
    "\n",
    "# Call the function to generate paraphrases with retry mechanism\n",
    "output = generate_paraphrases_gpt_with_retry(example_text, upsample_ratio, example_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the training dataset\n",
    "augmented_train_data = augment_dataset(dataset[\"train\"], total_counts)\n",
    "\n",
    "# Convert to DataFrame for easy inspection and saving\n",
    "augmented_train_df = pd.DataFrame(augmented_train_data)\n",
    "\n",
    "# Display the first 3 rows of the augmented data\n",
    "print(augmented_train_df.head(3))\n",
    "\n",
    "# Save the augmented data to a JSONL file\n",
    "augmented_train_df.to_json(\"augmented_train_data_test.jsonl\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, path: Union[Path, str], tokenizer, num_classes: int = 28, max_length: int = 256):\n",
    "        self.samples = []\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                self.samples.append(item)\n",
    "\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.num_classes = num_classes  # Number of classes for multi-label task\n",
    "        self.labels     = [s[\"labels\"] for s in self.samples]  # Multi-label list of labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        enc = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",  # Ensure padding is done to a fixed max_length\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Handle multi-label padding\n",
    "        label = item[\"labels\"]\n",
    "        label_vector = torch.zeros(self.num_classes)  # Initialize a zero vector of size num_classes\n",
    "        for l in label:\n",
    "            label_vector[l] = 1  # Set the class indices to 1\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),  # Remove the batch dimension\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),  # Remove the batch dimension\n",
    "            \"labels\": label_vector  # Return the multi-label as a binary vector\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "# 1) Point to your local “model” folder\n",
    "model_path = Path(__file__).resolve().parent.parent / \"outputs\" / \"goemotions_transfer2\" / \"checkpoint-12950\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)  # Correct tokenizer path\n",
    "\n",
    "# 2) Define paths to your train, validation, and test JSONL files\n",
    "base_dir = Path(__file__).resolve().parent.parent\n",
    "dataset_dir = base_dir / \"data\" / \"augmented_go_emotion\"\n",
    "train_path = dataset_dir / \"train.jsonl\"\n",
    "val_path = dataset_dir / \"validation.jsonl\"\n",
    "test_path = dataset_dir / \"test.jsonl\"\n",
    "\n",
    "# 3) Load train/val/test datasets\n",
    "train_dataset = EmotionDataset(train_path, tokenizer)\n",
    "val_dataset   = EmotionDataset(val_path, tokenizer)\n",
    "test_dataset  = EmotionDataset(test_path, tokenizer)\n",
    "\n",
    "# Get labels for each dataset\n",
    "train_labels = train_dataset.get_labels()\n",
    "val_labels   = val_dataset.get_labels()\n",
    "test_labels  = test_dataset.get_labels()\n",
    "\n",
    "# Log the dataset sizes\n",
    "logging.info(f\"Train dataset loaded with {len(train_dataset)} samples.\")\n",
    "logging.info(f\"Validation dataset loaded with {len(val_dataset)} samples.\")\n",
    "logging.info(f\"Test dataset loaded with {len(test_dataset)} samples.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
